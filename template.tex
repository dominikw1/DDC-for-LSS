%% bare_conf.tex
%% V1.4
%% 2012/12/27
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/
%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex,
%%                    bare_jrnl_transmag.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[conference]{IEEEtran}
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}



% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% For directly writing german umlauts uncomment the appropriate line for
% your operating system:
% Windows:
% \usepackage[ansinew]{inputenc}
% Linux:
\usepackage[latin1]{inputenc}
% Mac
% \usepackage[applemac]{inputenc}
% If none of the above lines work you can also try the following:
% \usepackage[utf8]{inputenc}



% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{cleveref}

% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% add custom packages
\usepackage{color}
\definecolor{tumblue}{rgb}{0, 0.4, 0.74}

\usepackage[backend=biber,  style=ieee, url=false,doi=false, isbn=false, citestyle=numeric-comp]{biblatex}
\addbibresource{references.bib}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

% Add the seminar's cover page
\input{coverpage}

%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
\title{Data-Driven Control for Large-Scale Systems: \\ A Survey}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Dominik M. Weber}
\IEEEauthorblockA{Technical University of Munich\\
Email: dominik.m.weber@tum.de}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}



% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
Large-scale dynamical systems pose fundamental challenges for classical control due to high 
dimensionality and modeling complexity.
Data-driven control offers an alternative by using measured data instead
of relying on first-principles models.
This survey reviews data-driven control methods for
large-scale systems, covering both data-driven modeling techniques and direct model-free approaches.
The control architectures of decentralised, distributed, and hierarchical control are discussed
with a focus on enabling scalability to large-scale systems.
The survey highlights the state of the art in
applying data-driven approaches to large-scale systems, including trade-offs and open research challenges.


\end{abstract}

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}\label{introduction}

%https://pdf.sciencedirectassets.com/791905/AIP/1-s2.0-S3050744825000106/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIEz4%2B%2Fkg9Y5%2FYfr7WeX1j8hZzSBIxjzt%2F%2Fap0%2FUOg3WEAiEA4aYwbCOiunuCF06Ku81ibq2LB27GQopCbdVd6TbNqaoqsgUIfhAFGgwwNTkwMDM1NDY4NjUiDGYg1FEumCZ7KGm%2BQiqPBd7779jTpyZpw3qHgX1UfChGnifRyLmU6Gx758auDRTE1lfE7xkFXShjmgEgD%2B4L1j0AZX%2BAqNv9iCAs1ufDJhpwuvn0MvJJsZWO%2Bam59GIjw9frUa8n0tpkEq9DPt%2F1L1XJJGTquEohPSaxpOMf7KenCa58IIs59L3erXOdaJR590sBMZeOcnKShlaUflkdmThvBHGS4Qrh6XaOg9phH2N0TU%2BReFbEqoslLTXLrogoGMGnBofRtSbwWL2PXHz7peR9WZLF10xHnmuXaxBm2lEtcznFlPp9okAIRlG8dtUcdmjrJoosewBxcwmY%2BrVGKIWOJJQLY%2BDXRSRHxVX7EMwaL%2FNRkjgjN3tHI9K7jsnMDR0iCT5L4ww6uq9CYs4%2FSQPynvWuxfCHYspPCt1o%2By79AgrTLFINXJj2bocRxPU5%2BZoKIHtXTahwp0XpSU078%2FkVGTTLalzlOi8Bs4NZOdQyFihoLwxvw7FOO7bN4tTCQp9h5wjh0WzLxo3lpSGenZL7qWctaEJ67RRQlfsJHnetBTFWDarmnUyvtIz2M5H92e%2FE6yGo4Bu1BfIx%2Bodbyfoe46H%2BdpzfUd8NwWsuSeWSL5NblSq6zjo8B1go44W65rAIjbtrjmqs%2BFeCWJ0lEvEnbJpf8E7rqkjHOGUgpiXZv2FVHlDlLnIjakhGLfa%2ByWc%2FFqHnZCKtDZkA%2FQMQ8LNaIsH1YYPDaWHD00otZO2kC3YEQQQM2emRBsS8sPMmyMhEja2QVL3NtPt8LsPTuzoT2DB7PNVMS9%2B1qli9wgvXaAEbCJjVi9aodbHXJuEmundCS%2FKKnMQYy%2Fv28nM4EBQlt%2Bd8pC0oMGt4tPB0jhzuohzvd4dpr6egxmddlbgw2PPhyAY6sQHDSwSxUhMSCj5VuxEUEG1UxwonZ2FwzcfGx%2FHBwqoFOiAhAXTQ3QuZIuK0jvjaEGv9A8OSwb8fed8PKnPAPu%2Fm4aBv6pNUrQ9YgJBG3LnwhFeAOt%2FPTG7uBGwM8DDrh5Q4iRX%2BpQK%2BIVixdTF7diwZBEi97rJEJxHHYxSr%2Bh8dNkHXFVckNU2YqyBYx8bCdIaqWXEHMRkTinweb1QKBhGvele3avTo0B7h4yosoFNcYDc%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251115T133547Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYUDP3E2MG%2F20251115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7c858a985fd1ace403ab7d9dd6fecf198999ddf5aa63f02e2cd87e3b4f70cd82&hash=e7d7780dacefe8dec9e39cada7c3e505326ce01c09b4833e54846d2ff3637589&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S3050744825000106&tid=spdf-6398be90-0a83-4ff8-8643-f0e0edb80f3f&sid=d24a09c8193a7449834b42f3eb10962b751egxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1e035f5d070552545056&rr=99ef22439c1203b8&cc=de&kca=eyJrZXkiOiJQdytLUUt5amQ0VTlHdjRwK1pvcENpeVF0QVllZjFKdHZaSGFaZDN4R05MRk42ekwxRTV4ZWZPMWNpNFhaT2tkeWhFZ2ViVDc0OFJubTQzKzlvMDJMTWFvOExUN2tqQ2VmM3Q5RGwwN2pvUk5zMUJ1dmFZSWRDckthRUhGdk5NUmNlV3haRzh6Z21GaExzMGJCb3RmQ3ExYzJkQXZMd01UYnFLaVdJaWV5ME4xVjZYUm82TT0iLCJpdiI6IjFjYWNiYTQ5NDc4NWJlZjM0ODE2MjUyMGE4MzgzOGJjIn0=_1763213765135

Large-scale dynamical systems arise in a wide range of application domains, including power networks~\cite{alzaareer2020development}, transportation systems~\cite{zheng2017platooning}, industrial processes~\cite{kumar2021industrial}, and multi-agent robotic systems~\cite{zhang2025toward}. 
Their defining characteristics, including high dimensionality and strong
interconnections, often render classical centralised control approaches difficult to model and
computationally prohibitive.
As a result, relying on first-principles models 
for control of these systems becomes increasingly costly and
error-prone as complexity scales~\cite{DDC_Overview}.

Data-driven control has emerged as a promising solution to some of these limitations. 
Instead of relying on explicit physical modeling, data-driven approaches exploit measured
system trajectories to infer models or synthesise controllers directly. 
This shift has enabled control designs for systems where traditional modeling is infeasible
or where operating conditions change over time~\cite{behavioralDataDrivenControl}.
However, the applicability of data-driven methods to large-scale systems is not solely determined by the choice of control framework.
Instead, maintaining computational tractability as system size increases hinges on how systems are decomposed, how information is exchanged, and how control decisions are coordinated across subsystems~\cite{ma2024efficient}.

While the literature on data-driven control is extensive, its interplay with large-scale system control scenarios has received 
less focus. Research on large-scale control architectures often assumes access to accurate models and does
not fully account for model uncertainties and difficulties for obtaining such models in real-world settings~\cite{xia2024predictor, aljohani2024tri, ma2024cloud}.
This survey aims to provide a structured overview of data-driven control for large-scale systems, emphasising how modeling choices, 
control paradigms and architectural design jointly determine scalability. 
It highlights scalable methods of both indirect and direct data-driven control and discusses centralised and non-centralised architectures.

The remainder of the survey is organised as follows. 
Section \ref{background} provides a brief background on data-driven control, large-scale systems and safety filters, the central
technique for providing formal guarantees for data-driven controllers.
Following is an introduction to direct and indirect data-driven control techniques, forming the basis for
large-scale deployment in non-centralised architectures.
Section \ref{modeling} reviews data-driven modeling techniques relevant to large-scale systems, enabling system decomposition and dimensionality reduction. 
Section \ref{modelfree} covers direct, model-free control approaches and their extensions to large-scale and distributed settings. 
Section \ref{architecture} discusses decentralised, distributed, and hierarchical control architectures, analysing how architectural choices affect scalability, 
coordination, and performance. Safety and robustness mechanisms are introduced, focusing on aspects necessitated by the system's scale.
Section \ref{conclusion} concludes with a brief discussion of open challenges and directions for future research.


\section{Background}\label{background}

% no \IEEEPARstart
\subsection{Data-Driven Control}


%\subsubsection{Classification}
A fundamental delimination in data-driven control can be made between direct and indirect approaches. 
In indirect methods, a model is learned from data - a process termed system identification (SI) - and, as in traditional control, a controller built upon it.
%Examples of techniques using this strategy are Koopman-theory~\cite{Korda_2018} and Gaussian process~\cite{Kocijan01122005} based approaches.
In direct data-driven control, the dynamics of the system are treated as a black box and the controller is directly built from the data~\cite{DDC_Overview}.



%\subsubsection{Advantages}

Data-driven approaches provide a range of benefits compared to traditional model-based ones. 
System identification, the basis for indirect data-driven methods, has
the key advantage of being generally applicable and to a large degree automated, 
whereas a model-based technique requires expert knowledge for deriving the model from first principles,
the specific result then being domain-specific. SI further provides the practitioner with 
tools to fine-tune the accuracy required, as complexity tends to rise with more accurate models~\cite{behavioralDataDrivenControl}.


Following is a brief overview of a selection of the most fundamental definitions and theorems in data-driven control,
which lay the basis for many of the concepts discussed in this survey. As a comprehensive treatment of
all mentioned terms is beyond the scope of this survey, the reader is instead referred to the corresponding cited literature.

A \textit{Hankel matrix} \(\mathcal{H}_{[N,T]}^i(x)\) derived from a dataset \(x\) with depth \(N\) and length \(T\) is defined as~\cite{VERHEIJEN2023100914}:

\begin{equation}
\begin{pmatrix}
x(i) & x(i+1) & ... & x(i+T-1) \\
x(i+1) & x(i+2) & ...  & x(i+T) \\
\vdots & \vdots & \vdots & \vdots \\
x(i+N-1) & x(i+N) & ...  & x(i+T+N-2) 
\end{pmatrix}
\end{equation}

A signal \(u = [u_1,\dots,u_T]\) is said to be \textit{persistently exciting of order \(L\)} if the 
Hankel matrix \(\mathcal{H}_{[L,T]}(u)\) has full row rank~\cite{coulson2019data}.
Based on this notion, \textit{Willems' Fundamental Lemma}~\cite{willems2005note} is built.
As presented in \cite{9062331} for the linear time invariant system 

\begin{equation}
  \label{willemssys}
\begin{aligned}
  x(t+1) &= Ax(t)+ Bu(t)\\
  y(t) &= Cx(t) + Du(t)
\end{aligned}
\end{equation}

with \((A,B)\) controllable, the input/state/output trajectory \(\left(u_{[0,T-1]},x_{[0,T-1]},y_{[0,T-1]}\right)\) with the stacked Hankel matrices 

\begin{equation}
\begin{pmatrix}
\mathcal{H}_{[L,T]} \left(u_{[0,T-1]}\right)\\
\mathcal{H}_{[L,T]} \left(y_{[0,T-1]}\right)
\end{pmatrix} = 
\begin{pmatrix}
u(0) & \dots & u(T-L)\\
\vdots & \vdots & \vdots \\
u(L-1) & \dots & u(T-1)\\
y(0) & \dots &y (T-L)\\
\vdots & \vdots & \vdots \\
y(L-1) & \dots & y(T-1)\\
\end{pmatrix}
\end{equation}

assuming the input \(u_{[0,T-1]}\) is persistently exciting of order \(n+L\), the following two statements hold:
Firstly, any input/output trajectory \(\left(\bar{u}_{[0,L-1]}, \bar{y}_{[0,L-1]}\right)\) is a trajectory of the system in \cref{willemssys} if and only if, for some real vector \(g\),

\begin{equation}
\begin{pmatrix}
\bar{u}_{[0,L-1]}\\
\bar{y}_{[0,L-1]}
\end{pmatrix}
=
\begin{pmatrix}
\mathcal{H}_{[L,T]} \left(u_{[0,T-1]}\right)\\
\mathcal{H}_{[L,T]} \left(y_{[0,T-1]}\right)
\end{pmatrix} g
\end{equation}

\noindent Secondly, the following matrix has full row rank: 

\begin{equation}
\begin{pmatrix}
\mathcal{H}_{[1,T]} (x_{[0,T-L]})\\ 
\mathcal{H}_{[L,T]} (u_{[0,T-1]})
\end{pmatrix}
= \begin{pmatrix}
  x(0) & \dots & x(T-L)\\
  u(0) & \dots & u(T-L)\\
  \vdots & \vdots & \vdots \\
  u(L-1) & \dots & u(T-1)
\end{pmatrix}
\end{equation} 



%For large and complex systems, automatic system identification hence   

\subsection{Large-Scale Systems}


Large-scale systems do not have a single clear definition.
The term is rather used whenever a system grows intractable to control with traditional strategies.
It is further often used synonymously with complex system, a system consisting of multiple interacting units 
that exhibits emergent collective behaviour which is not the simple summation of its parts~\cite{ControllingComplexSystem}.
% a system is considered as large scale complex whenever it is necessary to partition the given analysis or synthesis problem in order to come up with manageable subproblems
% https://pdf.sciencedirectassets.com/271897/1-s2.0-S1367578812X00026/1-s2.0-S1367578812000028/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDkaCXVzLWVhc3QtMSJGMEQCIFuyO2%2BOyv4oEbvlBReZXR12ei9IPZCW5zmPtdWgH3yKAiA9tGSvndkFQW4ktFpVnS7Qsqax0atoQRMRT95WTdkIZSq8BQjS%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMyC1wWjnrzaLee3m0KpAFWle6d2mOWXDum5AbJS67M%2BWWoPU5UwcCWNSgG1A4QurSwIMb4XcK%2FVAoWp%2Fez8tKQYpXc4iOecz8GlSMVK6EwDgAlExE7FEUiwHADa0mCyVxIRqQBuu4Dspt8jo7jGff1lkClIHVULoVR5HLXhw3%2B7wdV9Udtugea3i2Gojl%2FYGhyPoIlG3iKwNDnZKlZ76l06Kf%2BCxxqYbxkEi0%2Fkl%2F2YAtYdIv6cCAcDAQ3%2FM9wfY%2FSlMFnWKMiT5j6%2B3hAYWLn9Mkd5FoKcxQVzgWxwGTHbgXea9rtTbCHMgr5lnI9%2FdwhFOoDkeqaajGEd%2B8IbHRWmrcRUhN%2Bwc9IBNrYjneCmHx2rIMUSK5ErSqVixAWjw3WNdy%2BPQ5MoPCBjUi62BrQrtVAEfXbD%2FSyWfQuPPYXV7lJW9n%2BYGlx3laPojmCvif5VkJR%2BnPSD1ucw9lP70YEpsAgQr44ZoHmjxXp%2FaX0HJhDWERE%2BhYnQ2%2Fif6uDi3oQSl%2BJYHsC4LWxA75k1j2tCA%2B6X%2FTZzwLmIJqLVMdZH13lrIWoKvzBgruvo6haPj2O%2FWggr7YA6jBJNZ8lS5%2FZJL1q%2BgDYEQK%2FDZSin0XI9uNCD%2Bwhsg84qOJTBA2c%2BdKg7bV0S2t44rbrggC04ey8G%2Fg7zstch2h4l1bAmyNyGiwREnYoiZrE%2FKAzYoNNwK0rR9ejPQzu4WZ9hOcBSi98bQnQqbKuDLTR0xLRpqysqr0S6x0TTn2caVpnWATs5Nkc6mg0hwPeEPfTB%2B%2BEoFdu4wzgjP4Y9csvFWjLqgnxNyc3TtJ0y9db8URTV5m1QGII4%2FqUt1uf9MrJOmIj%2FG%2BrZzRx%2FZAwFB2cLDAazzZ0jhqdGmK08eHqxr4guwcfXAwoPOdxwY6sgEmFF1uMvj97RYxU1%2BbQXqJ4PBHdjI7J8%2B0pQSDELzqI4m2uYZ4n6b82bkqzp3aIxqTq8Pgo00jqnQdExaet83PyoVP7GeAxYPSyR4P7qTavpW%2BbF1otVHaGCsiKYwuBQYmqB0DVd4UIIPNgkXfVznTG0xY7cdL0c%2FPwc3xpNJO1Km9HSo615oRUSryJ1cULVsw%2BUpaasuWPwogTUiVP1bIGVDEkM8dI9KlFNGxeltS6%2BjI&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251009T093726Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQS55SIAW%2F20251009%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=6a6ac8d15b5cb6434913e9415a4b20dadbcab6e2e795f0a35a4424128e3a6b70&hash=c75fc87a3e3b7ed67b7f7e226f8bec06b27f3feb422145c63f846f91f5658e16&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1367578812000028&tid=spdf-063f0f87-4e00-43a6-b7ff-10f6f3764c08&sid=029b8ee71b7c5841003ae926bfe04b1834bagxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1e075d5907000a58510c&rr=98bce63c6fd7974a&cc=de
Application domains of large-scale system control are areas such as power generation and distribution, traffic and water networks, and industrial system processes, such as heating ventilation or supply chain management systems~\cite{kordestani2021recent}.


The central problem in controlling such systems is the scalability requirements they impose upon the controller, often reaching thousands of interacting entities~\cite{ControllingComplexSystem}.
Traditional first-principle-based control of such systems can be intractable to formulate and compute, while being sensitive to uncertainty~\cite{YU2025126253}, motivating the usage of data-driven methods.
Generally, techniques used to handle control of large-scale and complex systems include
reducing the model to a more tractable size through model order reduction methods,
utilising non-centralised control architectures and including 
communication protocols and interconnects between individual subsystems into the control model.  

%It has been shown that by imposing locality or separability, 
%many large optimal control problems decompose into parallel local %subproblems whose complexity does not grow with the total system size, 
%using techniques such as system-level %synthesis~\cite{wang2017separablelocalizedlevelsynthesis}.



Model Order Reduction methods tackle the problem of reducing the complexity of large-scale systems.
This technique attempts to generate reduced models reproducing the input-output behaviour 
of large-scale systems accurately enough for the desired use case.
Traditional model reduction methods fall into two categories: Singular Value Decomposition (SVD)-based and moment matching methods.
SVD-based techniques are related to the eponymous singular value decomposition.
Their core idea is the computation of controllability and observability 
Gramians, eliminating hard-to-reach and -observe states~\cite{lowenerIntro}. 
Their advantages include the preservation of stability and a computable error bound. 
While work is being done to make them more efficient using approximations \cite{numSolutionLargeScale, prajapati2022model}, their resource requirements
remain their main drawback~\cite{lowenerIntro}. A popular method in this class of model order reduction techniques is Balanced Truncation (BT)~\cite{balancedtruncationOriginal}.
Moment matching methods consider the problem of matching the coefficients of power
series expansions of the transfer function at selected points, reducing model reduction
to rational interpolation. They tend to be cheaper to compute than SVD-based methods, 
but do not provide as strong of theoretical guarantees, the preservation of properties depending on factors such as the choice of expansion points~\cite{ANTOULAS200419}.
A prominent example is Krylov subspace methods~\cite{freund2003model}.

%This distinction does not necessarily apply to the techniques themselves, though, but rather to their
%implementation. 

The second key approach taken to enable the control of large-scale systems is the decomposition of the centralised
control problem into smaller, more manageable control tasks distributed to sub-controllers.
A centralised controller often does not suffice for effectively controlling large 
scale systems, the necessity of multiple controllers even being part of some definitions of large-scale systems~\cite{kordestani2021recent}. 
Depending on the interaction between the controllers, such approaches can
be categorised into decentralised, distributed and hierarchical control architectures, in addition to hybrids thereof~\cite{kordestani2021recent}.

Control of large-scale systems can roughly be categorised into three distinct levels: node control, edge control and structural control~\cite{ControllingComplexSystem}.
Node control concerns itself with the immediate determination of dynamics of a subset of agents at the lowest, microscopic view.
Edge control works by dynamically adjusting the communication protocol between the individual agents.
In structural control, the network topology can be reshaped in order to guide behaviour at the macroscopic level.
Most works are concerned with node control, as this resembles the traditional single, small-system control the closest.
While not all layers might be controllable for a specific use-case, such as the network topology being fixed and unchangeable, the best results are usually achieved when considering all levels~\cite{ControllingComplexSystem}.

\subsection{Safety filters}

%\subsection{Safety \& Certification}

The inherent complexity of large-scale systems not only
challenges tractability, but also exacerbates
safety and certification concerns.
As data-driven controllers replace interpretable physics-based models,
formal guarantees must often be reintroduced. 
This section serves as an introduction to safety filters,
a popular approach for achieving formal guarantees in data-driven large-scale systems~\cite{zhang2023data, ahmad2025hierarchical,khaledi2025data}. 

A system \(\dot{x}(t)  = f(x(t), u(t))\) is called safe if 

\begin{equation}
\forall t\in \mathbb{R}_{\geq 0} x(t) \in \mathcal{X} \land u(t) \in \mathcal{U}
\end{equation}

where \(\mathcal{X}\) and \(\mathcal{U}\) are the state constraint set and the input constraint set, respectively~\cite{10266799}.

Unlike traditional model-based designs, 
learning-driven controllers must operate under 
epistemic uncertainty arising from limited data, 
unmodeled dynamics, and distributional drift. 
Consequently, a major strand of recent work focuses on 
safety filters. These filters are supervisory mechanisms that ensure system 
trajectories remain within a certified safe set, 
even when the underlying controller or policy is learned. Formally, a safety filter 
is a function \(\kappa: \mathbb{R}^{n_x}\times \mathbb{R}^{n_u}\to \mathcal{U}\)
which transforms the control signal (\(u(t) = \kappa(x(t), u_{contr}(t))\)) determined by the controller \(u_{contr}\)
such that safety constraints are respected, and the modification is minimal, i.e. minimizing 

\begin{equation}
\int_{0}^\infty||\kappa(x(t),u_{contr}(t))-u_{contr}(t)||dt
\end{equation}

Among these, three major methodological families 
dominate current research~\cite{10266799}: Control Barrier Function (CBF) 
approaches, Hamilton-Jacobi reachability-based methods, and Predictive control 
formulations.

%\subsubsection{Control barrier function (CBF) approaches}


For a known control affine system \(\dot{x} = f(x)  + g(t)u\), a 
Control Barrier Function can be defined as follows~\cite{jin2023robust}: 
a continuously differentiable function \(h: \mathcal{X} \to \mathbb{R}\) 
is a CBF if there exists an  extended class \(K_\infty\) function \(\alpha\):
\begin{equation}
\sup_{u\in \mathcal{U}} \dot{h}(x,u)\geq -\alpha(h(x))
\end{equation}

for all \(x\in\mathcal{X}\) where \(\dot{h}(x, u) = \nabla h(x)
f(x) + \nabla h(x) g(x)u\).

The key idea is that for the safety set \(S = \{x \in \mathcal{X} | \exists u \in \mathcal{U} \land h(x) \geq 0\}\),
any Lipschitz continuous controller \(u(t)\) is safe~\cite{ames2016control}.
While CBFs traditionally rely on explicit system models, recent research
has proven the viability of learning them from data as well~\cite{wang2022data,bajelani2025data}.


Hamilton-Jacobi reachability analysis computes the backward reachable tube, a collection of all initial states with trajectories eventually reaching a target set even under the worst-case disturbance.
For safety, this target set can be the set of all unsafe states, the backward reachable tube then representing all potentially unsafe, to-be-avoided states~\cite{borquez2024safety}.
While this approach is easily generalisable to many applications, scalability concerns can be a limiting factor~\cite{leeman2023predictive}.

Predictive safety filters 
enforce safety constraints by solving a constrained optimisation problem that minimally corrects the nominal control input.
At each time step, the filter predicts the future 
system evolution over a finite horizon and ensures
that all reachable states remain within the safety set.
A key concept is the use of backup trajectories, feasible fallback control sequences that guarantee the system can return to a terminal safe set even if the nominal policy becomes unsafe. 
By verifying the existence of such a backup trajectory
before applying the proposed control,
predictive safety filters ensure recursive feasibility and forward
invariance of the safety set~\cite{milios2024stability}.

% comparison: https://proceedings.mlr.press/v211/leeman23a/leeman23a.pdf


%CBFs rely on
%Lyapunov theory to determine inputs to a system that
%ensure set invariance.

%---
%
%
%Hsu et al.~\cite{hsu2025statistical} introduce conformal robustness,  
%robustifying finite-horizon stability
%and safety guarantees in data-driven nonlinear dynamical
%systems.
%Through a conformally robust control Lyapunov
%function (CR-CLF) and control barrier function (CR-CBF), 
%systematic closed-loop control designs with provable 
%finite-horizon stability and safety guarantees are enabled.


%\subsubsection{Reachability-based approaches}

%based on a set-based propagation
%of all possible system trajectories determined by the
%system inputs and disturbances.

%\subsubsection{Predictive control approaches}




\section{Data-Driven Modeling}\label{modeling}

To enable indirect data-driven control techniques, a model of the to be controlled system needs to be
identified. This section outlines data-driven modeling techniques suitable for large-scale systems,
beginning with system identification, where collected data is used to construct a model of the system's underlying dynamics.
Given the scale and structural complexity of modern interconnected systems, 
topology identification and decomposition is subsequently addressed, revealing the system's interaction structure and partitioning it into manageable subsystems.
Finally, for components exhibiting significant nonlinear behavior, Koopman-based lifting techniques are discussed, enabling the approximation of nonlinear dynamics through finite-dimensional linear operators.

\subsection{System Identification}

As large-scale systems tend to produce system models that are
unwieldy to handle, data-driven model order reduction techniques
receive special attention~\cite{baumann2022data}. Data-driven model order reduction methods rely
only on measured trajectories, frequency response data, 
or impulse responses and produce a reduced representation of the system's dynamics.


\subsubsection{Interpolatory approaches}

A widely used approach is data-driven interpolatory model reduction.
One such method, the Loewner framework, constructs a reduced linear
model from transfer-function data or sampled impulse responses~\cite{gosea2022data}.
The main element of the Loewner framework is the Loewner Matrix. For two lists of complex number pairs \(u_i, v_i\) and \(\mu_j, \lambda_j\), it is defined as follows~\cite{lowenerIntro}: 

$$\begin{pmatrix}
\frac{v_1-w_1}{\mu_1-\lambda_1} & \dots & \frac{v_1-w_k}{\mu_1 - \lambda_k}\\
\dots & \dots & \dots \\
\frac{v_q-w_1}{\mu_q-\lambda_1} & \dots & \frac{v_q-w_k}{\mu_q - \lambda_k}
\end{pmatrix}$$


The rank of this Loewner matrix then contains information about the minimal admissible complexity of the solutions of the interpolation.
The shifted Loewner matrix \(L_\sigma\) has the entries \(L_{\sigma_{ij}} = \frac{\mu_jv_j- \lambda_iw_i}{\mu_j-\lambda_i}\).
The key insight is that for a linear system, 
these matrices are directly related to the system's internal  % double check this - chatgpt
state-space matrices without needing to know them explicitly~\cite{karachalios2023data}.
The singular values of the Loewner matrix are used to determine the numerical 
rank of the system, which suggests the appropriate order of the reduced model.  
A sharp drop-off in the singular values indicates a good candidate for the 
reduced model's dimension. 
By selecting a small number of the largest singular values, 
one can capture the most important dynamics of the original system.
The reduced-order model's state-space matrices
are then directly computed from the projected Loewner matrices 
and the data vectors~\cite{lowenerIntro}. % double chekck
While the Loewner framework has been successfully employed in large-scale system scenarios~\cite{gosea2022data},
the \(\mathcal{O}(n^3)\) complexity of SVD and its sensitivity to noise~\cite{kergus2018data} necessitates
the usage of advanced implementation techniques, such as using a sequence of 1-dimensional Loewner matrices for the computation of the null-space of an \(n\)-dimensional one, as proposed in \cite{antoulas2024loewner},
reducing the time complexity to about \(\mathcal{O}(n^{1.4})\).


Another interpolatory model order reduction technique is the AAA algorithm~\cite{nakatsukasa2018aaa}, which builds rational
approximants adaptively by selecting 
interpolation points based on approximation error. 
This method is attractive when only frequency response data is available, 
as it balances accuracy and model complexity with minimal user intervention.
% How does it work??

\subsubsection{Balanced truncation methods}

Balanced truncation~\cite{balancedtruncationOriginal} is a widely successfully employed model order reduction technique for large systems~\cite{salehi2021mixed}, traditionally relying on controllability and observability Gramians and hence access to system matrices.
A data-driven reformulation is presented in \cite{gosea2021datadrivenbalancinglineardynamical}.
The fundamental insight driving this development is that BT does not use the Gramians directly,
but rather their product, which can be approximated from data. The results of the numerical BT method 
can get arbitrarily close to those of classical BT, depending on how many computational resources are allocated to the numerical quadrature.

As in the Lowener framework, the SVD involved grows computationally infeasible for matrices common in large-scale systems. Using extended Krylov subspace methods, 
a low-rank approximation to the corresponding Sylvester equations can be generated, greatly improving efficiency~\cite{wang2025data}. 
Another approach is to utilise the idea of the low-rank Alternating Direction Implicit method~\cite{benner2013efficient},
a popular method for handling the computational complexity in traditional BT settings~\cite{zulfiqar2025data}, and reformulate it for
data-driven BT, reducing the model using transfer function samples from the right half of the s-plane~\cite{zulfiqar2025compression}.

% some more, see below
%\subsubsection{Optimality-based approaches}

%For discrete-time systems, \cite{sakamoto2024data} proposes 
%a data-driven \(h^2\) model reduction technique leveraging the
%discrete-time Lyapunov and Sylvester equations, deriving 
%the data-driven gradient.

\subsubsection{Modal decomposition methods}

Proper orthogonal decomposition is one of the most widely used dimensionality-reduction techniques in dynamical systems.
The key idea is to approximate system trajectories by 
projecting them onto a low-dimensional basis obtained directly from data.
For a dataset \(X = [x_1x_2...x_m], x_i \in \mathbb{R}^n\), proper orthogonal decomposition seeks an orthonormal basis
\(U_r\in\mathbb{R}^{n\times r}\) that minimizes the projection error 

\begin{equation}
\min_{U_r^TU_r = I_r} ||X-U_rU_r^TX||^2_F
\end{equation}

This optimisation problem is solved by computing the singular value decomposition of the snapshot matrix \(X\). 
The dominant singular vectors define the reduced basis, and the singular values quantify the energy captured by each mode~\cite{eskew2023new}.


A closely related algorithm is Dynamic Mode Decomposition (DMD).
Given snapshot pairs \(S^- = [x_1, ... , x_{m-1}]\) and \(S^+ = [x_2, ..., x_{m}]\), DMD approximates the system by finding
a matrix \(A\) such that 

\begin{equation}
x_{k+1} \approx Ax_k
\end{equation}

The goal is to determine a low-rank subspace of \(A\) and through it represent system dynamics.
One first performs SVD on \(S^- = U\Sigma V^T\), truncating \(U\) and \(V\) to the first \(r\) columns and selecting the first \(r\) singular values from \(\Sigma\).
What value to use for \(r\) depends on accuracy requirements, though a typical choice is to have it retain
a specific fraction of information, such that

\begin{equation}
r = \argmin_j \frac{\sum_{i=1}^{j}\sigma_i}{\sum_{i=1}^n\sigma_i} < \tau
\end{equation}

One can then reconstruct \(A_r = U_rS^+V_r\Sigma_r^{-1}\).
Using the cheap eigen-decomposition \(A_rW = \Lambda W\), one can compute the DMD modes \(\Psi = U_rW\), which 
contain the essential information about the system's evolution and can be used to approximately predict the system's state at any point in time~\cite{HUHN2023111852}.

A drawback of DMD is its sensitivity to sensor noise, which stems from its nature as effectively a least-squares algorithm, resting on the assumption that the independent variable is noise-free~\cite{dawson2016characterizing}.
Making DMD explicitly aware of noise, e.g. using a Kalman filter~\cite{nonomura2019extended} or a total least-squares approach~\cite{hemati2017biasing}, 
solves this problem to some degree~\cite{takeishi2017subspace}, though potentially at the cost of computational stability~\cite{ohmichi2022stable}.
The scalability of DMD, dominated by the SVD, can be improved via approaches such as working on compressed data~\cite{brunton2015compressed}, 
exploiting multi-scale dynamics via explicit introduction of multi-resolution DMD~\cite{kutz2016multiresolution}, or embedding DMD into a probabilistic framework to
get a randomised DMD algorithm~\cite{erichson2019randomized}. 

\subsection{Topology Identification and Decomposition}

An aspect of system identification central for large-scale systems is
topology identification. Whereas classical SI seeks simply to determine 
compact dynamic representations, topology identification 
aims to discover structural information about the subcomponents of the system. 
In large-scale systems, the goal of modeling is often to 
identify a sparse structure therein. This lays the necessary basis for popular 
decentralised and distributed control techniques~\cite{ocampo2011partitioning}.
Formally, given a 
set of variables \(V\), a directed graph \(\mathcal{G} = (V,\mathcal{E})\) 
is to be determined from data, such that \((v,w)\in\mathcal{E}\) if \(v\) has a direct causal effect on \(w\)~\cite{DDC_Overview}.

The system is hence not considered as a single, coherent object
anymore, but rather as a collection of 
different interacting subsystems. 
The two primary decomposition methodologies are physical and numerical. 
In the former, the subsystems are defined by the physical components of the system, such as individual robots in a swarm~\cite{bakule2012decentralized}.
Numerical decomposition, in contrast, imposes such structure based on computational reasons,
partitioning the large-scale system into manageable subsystems~\cite{ocampo2011partitioning}.
The interaction topology of the system is essential to consider in such approaches,
as it provides information on the dynamical couplings, allowing strongly connected
components to remain within one subsystem, the motivation being that such
modular partitioning tends to improve performance
by minimizing inter-subsystem interaction~\cite{riccardi2025general}.

A widely adopted approach is the Sparse Identification of Nonlinear Dynamics (SINDy) framework~\cite{sindy}.
It constructs a library of candidate nonlinear functions \(\Theta(X)\) 
and identifies governing interactions via sparse regression based on the time-series data \(X = [x_1, ...,x_n]\): 

\begin{equation}
\dot{X} = \Theta(X)\Xi
\end{equation}

\begin{equation}
\Xi = \argmin_{\Xi} \frac{1}{2}||\dot{X} - \Theta(X)\Xi||_2^2 + \lambda ||\Xi||_1
\end{equation}

The resulting sparsity pattern in \(\Xi\) directly defines the 
data-driven interconnection topology. 
SINDyG~\cite{basiri2024sindyg}, an extension of the base SINDy method, 
incorporates the network structure into sparse regression, 
directly identifying model parameters explaining 
underlying network dynamics, allowing the 
capturing of small changes in the emergent behaviour.

Another family of approaches uses causal discovery from
time-series, generalizing Granger causality~\cite{grangerCausalkty} to nonlinear and
high-dimensional dynamics.
Methods such as PCMCI~\cite{pcmci} recover directed
interaction graphs by statistically testing predictive dependencies
in data, requiring no explicit model assumptions.
%Recent variants integrate sparse regression or kernel embeddings
%for improved robustness under noise and temporal correlation.


Once the interaction topology is estimated,
data-driven decomposition partitions the overall 
network into weakly coupled modules.
This step is essential for scalability, 
as it limits the dimensionality of each identification and 
control problem. Practical strategies include clustering based on 
finding highly connected subgraphs
with balanced number of internal and external connections~\cite{ocampo2011partitioning}
and spectral clustering on dynamic interaction graphs~\cite{TANG20187}.

%Despite being dissimilar in details, most graph decomposition
%algorithms, such as spectral algorithm [94], -decomposition
%algorithm [93] and Bordered Block Diagonal(BBD) decomposition algorithm [93], try to reduce the total absolute values
%of the weights of the edges that connect various subgraphs to
% minimum.
%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106217

% They can be classified
%according to the properties of subsystem-interconnection structures as
% Disjoint subsystems
% Overlapping subsystems
% Symmetric composite systems
% Multi-time scale systems
% Hierarchically structured systems



%The decomposition
%algorithms are based on graph-theoretic representations such as
%epsilon decompositions, Bordered Block Diagonal (BBD) ordering,
%and input/output constrained decompositions.

%Graphical models, sparse identification, factorized dynamics, Koopman ensembles per locality.
%Mean-field reductions for dense homogeneous populations.

%\subsection{Surrogate \& Probabilistic Models at Scale}

%Sparse GPs, ensembles, bootstrap uncertainty, neural net surrogates with uncertainty quantification.
%How to scale UQ: sparse approximations, local GPs, Bayesian neural nets caveats.



\subsection{Koopman lifting for Nonlinear Subsystems}

% TODO: look at this again
For subsystems with strongly nonlinear dynamics, linear models identified via traditional system identification techniques are often inadequate~\cite{abbas2024survey}.
A recent trend in control of nonlinear systems is the usage of methods based on the Koopman operator~\cite{abtahi2025efficient, zhang2025deep, lin2025estimating, bakker2025time}.
Koopman-based methods lift the state to a space of observables where the nonlinear evolution can be captured exactly or closely approximated by a linear operator. 
This enables the use of linear control and estimation tools on inherently nonlinear subsystems while retaining the structure and couplings of the full system.
For large-scale systems, this approach allows scalable controller design, bridging the gap between nonlinear subsystem behavior and the computational advantages of linear control.

Formally, the Koopman operator \(\mathcal{K}_f: \mathcal{F} \to \mathcal{F}\) associated with the state transition map \(f: X\to X\) 
and the Banach space \(\mathcal{F}\) of observables \(g: X \to \mathbf{C}\) is defined through the composition 
\(\mathcal{K}_f g = g \circ f, \forall g \in \mathcal{F}\).
The two core properties making the Koopman operator an exceedingly useful tool are its globality and linearity~\cite{mauroy2020koopman}.
The Koopman operator provides an exact linear approximation 
to nonlinear systems that is globally valid, instead of only around a point or trajectory. 
The main drawback, however, is that it can be infinite-dimensional~\cite{shi2024koopman}.

%Recent research has focused on developing a Koopman MPC technique where one learns a linear 
%predictor (via Extended Dynamic Mode Decomposition or neural nets) and then solves a convex MPC on the lifted space~\cite{LI2025100219}.


A Koopman-invariant subspace is the span of a set of \(m\) basis observable functions \(y_i\)
if all functions \(g\) lying in this subspace, i.e. \(g = \sum_{k=1}^m \alpha_ky_k\)
remain inside this subspace upon application of the Koopman operator, there being a linear combination of the basis functions representing \(\mathcal{K}g\),
\(\mathcal{K}g = \beta_1y_1 + \beta_2 y_2 +  ... + \beta_m y_m\)~\cite{brunton2016koopman}.
On this subspace, a finite-dimensional linear operator \(K\) can be obtained, restricting the Koopman operator \(\mathcal{K}\) and
describing the linear evolution of lifted observables~\cite{shi2024koopman}.
When applying the Koopman operator to control scenarios, a Koopman-invariant subspace containing the original state variables \(x_i\) is desired.
This can be an impossible task for some systems, for example, a system with multiple
fixed points, as all finite-dimensional linear systems have a single fixed point~\cite{brunton2016koopman}. 

The data-driven determination of the Koopman operator's spectral properties usually involves projecting the infinite-dimensional operator onto a finite-dimensional subspace of observables~\cite{meanti2023estimating}.
This finite-dimensional approximation is obtained directly from data, hence no intermediate high-dimensional system to be reduced afterwards is identified.
DMD~\cite{schmid2010dynamic} is a popular technique, in large part due to its ease of implementation~\cite{dmdImpl}, extensibility and interpretability~\cite{tu2013dynamic}.
The procedure begins by collecting a time-series of state 
snapshots and organising them into two matrices, 
\(X\) and \(Y\), representing paired snapshots of the 
system's past and future states, 
respectively.
The core objective is to determine the best-fit linear 
operator \(A\) such that \(Y \approx A X\). 
To ensure robustness and manage high-dimensional data, the method 
utilises the SVD of the state
matrix \(X \approx U_r \Sigma_r V_r^*\) to project the 
dynamics onto a rank-\(r\) subspace~\cite{kutz2016dynamic}. 
The low-rank approximation of the Koopman operator is then calculated as
\(\tilde{A} = U_r^* YV_r\Sigma_r^{-1}\)~\cite{schmid2010dynamic}.

Another widespread~\cite{Rowley2009SpectralAO} method for linear functions is tICA~\cite{tICA}.
The methods of eDMD~\cite{Williams2014ADA}, VAC~\cite{vacsem}, KernelDMD~\cite{kerneldmd} and kernel tICA~\cite{schwantes2015modeling} extend the function dictionary to non-linear functions~\cite{meanti2023estimating}.
The latter two kernel techniques resort to being infinite-dimensional, trading off computational efficiency for theoretical guarantees~\cite{koopmanThepry},
though approximate kernel methods are a topic of active research~\cite{baddoo2022kernel, meanti2023estimating, liang2025fourier}.

Despite their theoretical appeal, Koopman-based approaches face well-documented limitations in large-scale settings. 
First, finite-dimensional Koopman-invariant subspaces rarely exist for nonlinear systems of practical interest, 
causing lifted linear models to incur rapidly growing approximation errors~\cite{brunton2016koopman}.
Second, the observable dictionaries required for expressive embeddings scale combinatorially with system complexity, 
making both eDMD-type methods and dictionary learning computationally prohibitive at large scale~\cite{mauroy2020koopman}. 
Kernelised variants partially avoid explicit feature construction but introduce \(\mathcal{O}(N^2)\) to \(\mathcal{O}(N^3)\) computational cost
in the number of snapshots, which quickly becomes intractable without sketching or other aggressive approximations~\cite{meanti2023estimating}. 
As a consequence, while the application of Koopman theory to ever-larger systems is currently a vibrant field of research, 
Koopman lifting remains viable only for moderate-size nonlinear subsystems with coherent low-dimensional
structure rather than arbitrary full large-scale networks.


\section{Model-Free Control}\label{modelfree}

Instead of data-driven modeling, where data approximates the
underlying system to enable model-based control, an orthogonal strand of research
eliminates explicit modeling altogether. 
Such model-free direct data-driven control paradigms, chiefly among them 
Data-enabled Predictive Control (DeePC) and 
Reinforcement Learning, 
have received much attention lately.

\subsection{Data-enabled Predictive Control}

Data-enabled Predictive Control~\cite{coulson2019data} is 
a model-free control framework that extends 
the principles of Model Predictive Control (MPC) 
to a purely data-driven setting.
It eliminates the need for explicit 
system identification by leveraging Willems' Fundamental
Lemma~\cite{willems2005note} from behavioural systems theory, 
which states that all trajectories of a
controllable linear system can be represented
as linear combinations of a single persistently
exciting trajectory.

Given a persistently exciting input-output dataset, DeePC constructs Hankel matrices of past inputs and outputs, then formulates
an optimisation problem that directly predicts 
future trajectories and computes optimal control actions 
without identifying a model. As described in \cite{coulson2019data}, the DeePC works as follows:
Taking as input a reference trajectory \(r\), past input-output data \((u_{ini}, y_{ini})\), constraint sets \(U,Y\) and performance matrices \(Q\) amd \(R\),
the first step is to solve for \(g^*\):

\begin{equation}
\label{deepc1}
\min_{g,u,y} \sum_{k=0}^{N-1}||y_k-r_{t+k}||_Q^2 + ||u_k||_R^2
\end{equation}

subject to

\begin{equation}
\label{deepc2}
\begin{bmatrix}
U_p\\
Y_p \\
U_f \\
Y_f
\end{bmatrix}
g
= 
\begin{bmatrix}
u_{ini}\\ y_{ini}\\ u \\y
\end{bmatrix}, \forall k \in [N-1]: u_k\in U, y_k\in Y
\end{equation}

The optimal control sequence is subsequently calculated via \(u^* = U_fg^*\).

Since its introduction, a variety of extensions have 
been proposed to enhance the robustness, 
scalability, and practicality of DeePC.
To improve noise tolerance and generalisation 
to unseen conditions, regularised DeePC formulations
introduce penalties on the trajectory coefficients
and slack variables, effectively mitigating overfitting
to specific datasets~\cite{ramadan2025floodgatescontaindeepclimit}.
Scalability can be improved greatly by adding a dimension reduction step to the traditional DeePC 
technique. This involves performing a low-rank approximation of the trajectory matrices via SVD, which reduces the number of decision
variables in the underlying optimization problem while
maintaining the dominant system dynamics~\cite{wang2024mechanical}.

Its applicability to large-scale systems is primarily driven through 
distributed and hierarchical DeePC
algorithm formulations, decomposing the 
global DeePC optimisation into coupled
subproblems solved locally with limited coordination,
improving scalability and communication efficiency~\cite{YU2024110360,10667672}.

The extension of DeePC to the control of nonlinear systems has been a focus of recent reserach, 
primarily through the usage of kernel functions~\cite{huang2023robust,de2025kernelized}.
While these works have considered computational efficiency,
real-time applicability remains limited, \cite{huang2023robust} incurring a slowdown by a factor of almost ten over the original DeePC implementation.
In the context of large-scale systems, these methods should hence be reserved for the control of strongly nonlinear subsystems.

Recent works further address online computational efficiency through recursive
and low-rank DeePC updates, allowing adaptive, 
real-time control under streaming data constraints~\cite{shi2024efficient}.
The DeePC formulation is transformed into a low-dimensional 
form via SVD. Then, a fast SVD update mechanism is provided
to avoid recomputing everything from scratch every time new data arrives.
This drastically improves online use viability.


DeePC-style control can be made robust, as proposed in \cite{huang2023robust}, 
a computationally tractable reformulation of DeePC's traditional min-max optimisation
problem via uncertainty sets, providing performance guarantees for the open-loop realised input/output cost.
For partially known systems, hybrid data-enabled predictive control~\cite{watson2025hybrid}
presents an approach providing improved computational cost and robustness
via an inclusion of model knowledge into DeePC. 

Safety constraint satisfaction in DeePC has largely been achieved via
hybrid control architectures~\cite{bold2025two}, 
where a secondary controller 
activates when the predictive controller cannot guarantee satisfaction of output or trajectory constraints, and 
via data-driven reachability analysis~\cite{li2024robust}.
Hybrid designs offer flexibility and can be computationally efficient, but they are not specific to DeePC.
Meanwhile, reachability analysis scales poorly with system size~\cite{leeman2023predictive}, limiting the applicability of this approach to large-scale systems.
Consequently, the development of safety mechanisms for DeePC that remain computationally tractable for high-dimensional systems remains an open challenge.

\subsection{Reinforcement Learning}

Reinforcement Learning (RL) has recently become a popular 
method for dealing with the ever-growing complexity of modern systems, 
providing the benefit of determining optimal control policies without 
necessitating detailed system models~\cite{9261330}.
RL-based controllers require no labelled datasets and are instead guided by feedback and learn in a trial-and-error fashion,
making them well-suited for large-scale systems where 
explicit system models are missing~\cite{rfAndIntro}.

Another advantage of RL is its statement of the control problem as Markov decision processes
(MDPs), providing great generality. 
They are applicable to nonlinear
and stochastic dynamics, nonquadratic reward functions and even
continuous states and actions through numerical
function approximation techniques~\cite{BUSONIU20188}.
Weaknesses include high data requirements and long convergence times~\cite{BARBALHO2022108315},
hyperparameter sensitivity~\cite{smartGridRL}, potentially high computational costs, and  
often missing formal stability guarantees~\cite{BARBALHO2022108315}.



%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11162524 this is good

%In the context of microgrids, an RL agent might take the following form~\cite{mfrlMG}:

The goal is to find a policy \(\pi: S \to \mathcal{A}\) mapping 
states to actions maximizing the expected cumulative reward

\begin{equation}
J(\pi) = \mathbb{E}_\pi \left[\sum_{t=0}^\infty\gamma^tr(s_t,a_t)\right]
\label{eq:reinforcement}
\end{equation}

\noindent \(\gamma\in [0,1]\) denotes a factor balancing immediate against
long-term goals and \(r\) encodes control objectives as scalar rewards, possibly differing across individual controllers, e.g. in hierarchical systems~\cite{mfrlMG}.

To enable real-time online reinforcement for large-scale systems,
approximation approaches have been proposed, where the input-output history is
transformed into a shorter set of data, being the basis for a lower-dimensional
inferred controller than the original, decreasing the time complexity from \(\mathcal{O}(n^6)\) to \(\mathcal{O}(L^6)\), 
where \(n\) is the state vector size and \(L \ll n\) represents the length of the input-output data history considered~\cite{sadamoto2021fast}.
As a guideline for choosing a value for \(L\) that still results in a nearly optimal controller, the authors propose
a SVD-based algorithm that determines \(L\) based on a threshold value for the singular values with a complexity of \(\mathcal{O}(L^4)\).


A central distinction is to be made between online and offline RL.
Traditionally, RL is viewed as an active
learning process requiring interaction with the environment. 
This can, however, be expensive and dangerous,
and must rely on a smaller set of data than could be gathered for offline datasets, 
due to them only having to be collected once, instead of during each run~\cite{conservativeQLearning}.
Offline RL methods, the learning from entirely pre-collected, offline data, without on-policy interaction, 
have been developed accordingly. Challenges to be solved with this approach include the inability of exploration, 
the counterfactuality of queries and distributional shift~\cite{Levine2020OfflineRL}.
The learned policy may select actions that are poorly represented
in the dataset, leading to extrapolation errors in value estimates.
To mitigate this, a range of regularisation strategies have been proposed.

One range of technique centres around the 
idea of Conservative Q-Learning~\cite{conservativeQLearning}.
Conservative Q-Learning solves issues off-policy RL algorithms face by learning a conservative estimate of the value function,
avoiding over-estimation and yielding much better
performance. A tighter lower bound is achieved by 
Mildly Conservative Q-learning~\cite{mildlyconservativee}, actively training out-of-distribution actions by constructing them proper
pseudo target values. 

Offline RL has also been extended to multi-agent and distributed settings. Counterfactual Conservative Q-Learning proposes a method  
counterfactually determining conservative regularisation
for each agent separately and subsequently combining them linearly, leading to an overall conservative estimation~\cite{NEURIPS2023_f3f2ff95}.

To achieve robustness in reinforcement learning, the maximization problem presented in \cref{eq:reinforcement}.
can be reformulated, depending on where the uncertainty is assumed to stem from~\cite{moos2022robust}. In the case of an unknown transition matrix \(P\), fixed and lying within a known uncertainty set \(\mathcal{U}_P\), this might look as follows:

\begin{equation}
\max_{\pi\in\Pi}\min_{P\in \mathcal{U}_P}\mathbb{E}_{P,\pi} \left[\gamma^t r(s_t,a_t)\right]
\end{equation}


Since reinforcement learning approaches make random decisions in the process of exploration
that can violate safety constraints and lead to unacceptable system behaviour, naive RL methods
cannot be applied to many safety critical areas~\cite{yu2024safe}.
One approach to safe RL is to utilise Lyapunov functions determined through linear programming to
guarantee safety and robust learning~\cite{chow2018lyapunov}.
An alternative methodology involves adding CBFs, dropping the reward to minus infinity in
safety violation situations, ensuring the learned optimal control policy respects the safety bounds~\cite{vu2021barrier}.
These CBFs can further be learned efficiently using neural networks, as demonstrated by \cite{yang2023model},
improving this method's applicability to large-scale systems.
A formal-methods-based approach presented in \cite{hasanbeig2020cautious} safety constraints 
expressed in LTL guide the exploration. A key drawback of this, despite success in the safety dimension, is the necessity of manual 
formulation of these constraints~\cite{gu2024review}. 


\section{Control Architectures for Large-Scale Systems}\label{architecture}

% https://pdf.sciencedirectassets.com/777797/1-s2.0-S2666792424X00025/1-s2.0-S2666792424000155/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGkaCXVzLWVhc3QtMSJGMEQCIAegW7oXZKt3V9iBiEi2msqM%2BAY9A%2BPnHt18CO8%2BJYaCAiBoGcwAz5MjgiQ%2B4cRBI8XgsRtqQCxLZFfd4fvDJoqWRSqyBQgxEAUaDDA1OTAwMzU0Njg2NSIMMYuZTXbWxxUOh%2FfyKo8Fye1UeN2ILOpLtc%2FIb2pNV5TpvXUMeJG9ty9tlHXnkecB3WvX2h9g%2FH0P8NpDY6ufHHbh5cpFPlre%2FdfskqzV6o%2FblkED1IVm2WmMlZcSjkMZmht0AoQvX2oRH%2BuLGlSYpZlJAYUps1c%2BsgAnXlyXTOIYjBuzacVG6NB7rpVKsvgdzW2gnkxqjLz%2BnsS3CgAUPivEIVnN%2BG%2BAaQjLhSpKw%2Ba80Lp6alALVrJVc%2FVhfYZm4%2FJsgBuscEXsc5CJjLUUlY4Nus%2FFuSf7BIdTHTsI89VhQr5zPnKIpctRYlrxYMq8dHCKQMXJvZReLhUGUgLDhZMRqxm%2Fnn8OlN9ST%2FfSuN%2BKp4yVQI19TjGDLYHVegb032PEwh3twWlj8IVxNypcBq0r%2BW0Z2eeO%2F3PsfL1LOZJIEZrh2k9WGr%2Bv%2BERbOexA6KLvTGp2v4PVhFjD9m3GTaZmKuCUNI7qhbrGHAr26g2wFuWWGNahHxekZKxz6UijxHnMRuM5%2BnBkLB40NT2ewjbT4RdIjXJC4k4Y2uOFe9Xg8ySbHDpq1%2FbtwiiKqD75807SeBlKjkNbYmXj1decWIJuzDzEh1SqkPr6qb%2B4DbKtbok2txp5aSSBmTNjA%2FB8CsPGFh3LKIM5q5nVAFHTifdCcAPF0mR%2BeIjya0UL%2BRiW84hqopNC0upT2vN0gXHJ%2B9lV5Hw2n3HNnyughWW0A8cZVKyrxM%2BLh1giUBGUJ4gVfJeK7gTnT4HRSTETrW0%2BOT%2Bbv4yTc1CHrd9kacMp1S%2FlxJOcaT%2F5nUHbeX8qXOscXPlW5LN7hAuNS4MStaa1sSxcTQ29UEVL%2FQZ2%2BM%2BRziaJAzeR2V5DzJOAchRh5rc5w3VEgQu78PntDJ%2BQjjCA4PnJBjqyAaYDkrd09y6EdJPfV%2B1ANuT%2FlIKHvBfvvEXvUML6COsvmNPtlpliOUUuULrXC41pdkrcnPWKqgKyyDa%2B8zmlg2xdDJUMpW1Myf96IMiFjwiEs29tIjR29L5qvd83Tw8l9ogGK0I4MCtuK06bTav5TccoqYdDuVm1ckAT20DqiGIDWSRPqoQjHitHLnfVSAkk4%2FgPka0WFemDutl%2B3Y4P1BIwjw%2Byx81lKKhLoWRKQRDt%2BGY%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251214T091122Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYT2S7FDUI%2F20251214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=5d489fcf529487e486b06c5ecba3a76628a5ea534a8b7bf1bee25a8726ad7f33&hash=bed937f3c0baeabfb6c35e812db2d332048e195209781c435cf7e2ec4583b357&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2666792424000155&tid=spdf-884412dc-733d-4aba-a099-204207f7dde7&sid=74e7365b827934490d489a73f00ba09a78eegxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1b125f05060059540700&rr=9adc92ceadbb8f2b&cc=at


The scalability of data-driven control 
depends not only on the learning or 
identification methods employed, but also on the 
architecture through which control decisions are coordinated.
The control architecture determines how information
is shared and decisions are made within a large-scale
system.
Large-scale systems pose fundamental challenges for classical control architectures.
As system dimensions and interconnections grow, centralised strategies become computationally intractable and communication-limited~\cite{ma2024efficient}.


To address these challenges, the three principal paradigms of decentralised, distributed, and hierarchical control have evolved, each with characteristic trade-offs 
in scalability, performance, and robustness. 
Beyond this tripartite classification, 
modern work increasingly integrates hybrid architectures, 
blurring traditional boundaries.


\subsection{Decentralised control}

In decentralised control, each subsystem maintains 
an independent controller relying solely on local 
measurements and actuation. 
No online communication occurs among controllers, 
and couplings are treated as exogenous disturbances or 
modeled implicitly~\cite{wang1973stabilization}.
This structure yields high robustness to communication 
failures, straightforward scalability
and is attractive for large-scale systems where global data aggregation is infeasible or 
undesirable due to privacy, latency, or safety concerns, 
yet typically sacrifices global optimality, as individual controllers do not have as much information regarding the state or output of the system as a centralised one would~\cite{ge2017distributed}.
In some definitions of decentralised control, information exchange is allowed before and after the decision-making process, 
simply restricting the controllers from actively negotiating~\cite{bemporad2010decentralized}. 

% https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127863&casa_token=Ko36uD2854kAAAAA:ynMRD7IwURNZU4uS1boXJgMnyyIX5uHKjdMOfL0Iw4WQ6snn9hCol0oUsfaFqD-1IQBFxbjnBWaB9A
% https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10053641&casa_token=omf8nd2_9yAAAAAA:A8q6bRC4elyGWE9BYTfH8e01ilCE7Hmjpn_huSnY8rP8ZyhpDaHSAx2UrLYWgXHLCidFqDq9gIRuFw
% https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127863&casa_token=Ko36uD2854kAAAAA:ynMRD7IwURNZU4uS1boXJgMnyyIX5uHKjdMOfL0Iw4WQ6snn9hCol0oUsfaFqD-1IQBFxbjnBWaB9A


A natural approach to decentralised control is the extension of the popular MPC to this setting. 
In general, data-driven MPC can be formulated as presented in \cite{10535441}.
Given input-output data for the last \(\rho\) timesteps \(\mathbf{z}_t = [u_{t-\rho}^T ... u_{t-1}^T y_{t-\rho}^T ... y_{t-1}^T]^T\) and 
denoting the \(T\) future inputs and predicted outputs as \(\mathbf{u}_t = [u_t^T ... u_{t+T-1}^T]^T\) and \(\mathbf{\hat{y}}_t = [\hat{y}_t^T ... \hat{y}_{t+T-1}^T]^T\), respectively, 
the goal is to minimize some some finite-horizon criterion \(J(\mathbf{u}_t, \mathbf{y}_t)\). With reference trajectory \((\bar{\mathbf{y}}_t, \bar{\mathbf{u}}_t)\), this could take the form of the quadratic criterion

\begin{equation}
J(\mathbf{u}_t, \mathbf{y}_t) = ||\mathbf{y}_t - \bar{\mathbf{y}}_t||^2_Q+ ||\mathbf{u}_t - \bar{\mathbf{u}}_t ||^2_R
\end{equation}

The finite-horizon predictive control problem is then given by the equations, provided constraint sets \(\mathcal{U}\) and \(\mathcal{Y}\):

\begin{equation}
\min_{\mathbf{u}} J(\mathbf{u}, \mathbf{\hat{y}})
\end{equation}

\begin{equation}
\mathbf{\hat{y}} = \text{Prediction}(\mathbf{z}, \mathbf{u}), \mathbf{u} \in \mathcal{U}, \mathbf{\hat{y}}\in \mathcal{Y}
\end{equation}

For each timestep, the optimisation problem can be solved and the first optimal input component
applied to the system, repeating until convergence~\cite{berberich2024overview}.

The predictor can be either model-based or computed directly from the training data.
As a simple illustration, a linear model for predicting the measurements is given by \(\hat{\mathbf{y}}= \hat{\Theta}\phi(\mathbf{z},\mathbf{u})\),
\(\phi(\mathbf{z}, \mathbf{u})\) being a regression vector and \(\hat{\Theta}\) the vector of estimated parameters.
A direct instantiation of data-driven MPC is the DeePC method presented in \cref{deepc1} and \cref{deepc2}.
Mattson et al.~\cite{10535441} showed that a range of direct methods is equivalent to an indirect method with a slack
variable in the predictor.

To illustrate the changes in a decentralised MPC method,
the linear dynamics of the the \(i\)th subsystem controller in a model-based view could be described as~\cite{kofler2022agent}

\begin{equation}
\dot{x}_i = Ax_i + B u_i +Ex_c
\end{equation}

where \(E\) denotes the disturbance based on the central state \(x_c\), one of its sources being the actuation from other subcontrollers.

Chen et al.~\cite{chen2020decentralized} propose a decentralised MPC system for nonlinear processes
where neural network models are trained for each subsystem and used as prediction models. 
This approach resulted in improved computational cost compared to the centralised approach, while ensuring 
closed-loop state boundedness and convergence.
Decentralised MPC can even work in application domains that tend to favour 
a different kind of architecture, such as microgrids \cite{karami2019decentralized}.

The more popular approach to predictive control in decentralised architectures is the DeePC one, though.
dDeeP-LCC~\cite{shang2024decentralized}, a decentralised formulation of DeePC, achieves better safety guarantees and smaller computational cost than a centralised formulation, while being naturally privacy preserving.






%Recent research focuses on enhancing local 
%data-driven controllers with structural 
%priors and regularization that implicitly 
%encode coupling information. 
%Markovsky et al. [1] demonstrated that 
%behavioural system identification can yield locally 
%data-driven DeePC controllers with guaranteed 
%feasibility and stability in power networks, without 
%requiring explicit coupling models. 
%Di Lorenzo et al. [2] introduced continuification 
%control, a density-based approach where each agent 
%reconstructs a local estimate of the global state 
%density from sparse samples, achieving emergent global 
%coordination from fully local data. In large-scale 
%energy systems, 
%Yu et al. [3] combined local identification and 
%reinforcement-based optimisation to enable a
%daptive voltage and frequency control in 
%distributed grids.



%Despite its scalability and resilience, 
%purely decentralized data-driven control 
%remains challenged by incomplete information 
%and model drift. Current research therefore 
%emphasizes local adaptation - re-identifying models or
%updating policies online to preserve performance as 
%operating regimes shift. 
%Robustness to unobserved couplings and noise remains 
%a core open problem.



%https://pure.tue.nl/ws/portalfiles/portal/167568910/1312561_Anupama.pdf
%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810289&casa_token=0MxFKu6tynsAAAAA:28_1yQLNbASP1_ldp1jf39HW8Ol3EEJ7Ru8A81yKw7theSVp4tLAlQepsyR-KnBVNG77H6e85PvPxw

\subsubsection{Robustness}

Robustness in decentralised data-driven control addresses 
the challenges of uncertainty in subsystem interactions and
disturbances acting on local dynamics. 
Unlike centralised architectures, 
decentralised controllers cannot rely on global state
information, making explicit robustness formulations essential
for guaranteeing stability and constraint satisfaction
under limited information exchange.

A central approach to robust decentralised predictive control 
introduces bounded uncertainty sets for each subsystem.
These sets capture not only local disturbances and measurement noise, 
but also partially observed inter-subsystem coupling and network effects.
This method has been successfully employed in the context of
both predictive control~\cite{s22228709,shang2024decentralized} and
adaptive dynamic programming~\cite{li2023decentralized} in decentralised architectures.

Overall, decentralised robustness mechanisms scale well computationally, 
with approximately constant online complexity per subsystem, as they avoid global optimisation and communication entirely.
However, this scalability tends not to stem from exploiting the large-scale structure of the system,
but is rather a consequence of a naive decomposition of the global robustness goal
to the subsystem level, yielding limited system-level robustness guarantees under strong coupling conditions.



%Distributionally robust formulations achieve this by 
%optimising against ambiguity sets of empirical data,
%yielding probabilistic guarantees on constraint satisfaction~\cite{coulson2019regularised}.
%Alternatively, reachable-set or zonotopic constructions
%can be derived from local data to bound the effect of
%coupling and noise without explicit model identification~\cite{alanwar2022robust}.




%
%These uncertainty sets can be constructed empirically
%from measurement data, statistical confidence intervals,
%or physical limits on system evolution[CITE].
%
%Shang et al.~\cite{shang2024decentralized} proposed
%such a decentralized robust
%data-driven predictive control scheme, where each subsystem
%estimates a time-varying disturbance bound from local observations
%and embeds it into the predictive optimisation.
%The resulting controller achieves smooth and safe closed-loop behaviour
%even under strong coupling uncertainty.
%Comparable ideas have also been successfully applied in other domains, 
%such as robust decentralized control for microgrids, 
%where local controllers compute data-driven disturbance 
%bounds using voltage and power measurements to maintain
%grid stability under communication and measurement noise~\cite{s22228709}.
%
%
%Robustness can then be incorporated into the local optimisation in several ways.
%The most direct is the min-max formulation, 
%where each subsystem solves a saddle-point problem ensuring
%feasibility for all admissible uncertainties within its set. 
%While this approach provides strong guarantees,
%it can become conservative and computationally demanding, requiring
%careful engineering to maintain practical employability~\cite{xie2026data}.
%
%Constraint tightening and tube-based schemes are
%often preferred in practice.
%In these formulations, a nominal data-driven controller
%is augmented by a local feedback law or margin
%that confines the closed-loop trajectory within
%a robust invariant tube around the nominal prediction,
%maintaining safety without excessive conservatism~\cite{coulson2019regularised,shang2024decentralized}



%The application area of microgrid control has brought about much of the research on robust decrentralised control approaches.
%As for model-based methods, \cite{baghaee2017decentralized} proposes a decentralised robust mixed \(H_2/H_\infty\) controller

%\cite{li2023decentralized} proposes a robust adaptive dynamic programming approach to decentralised control taking into account both actuator faults and external disturbances. 



\subsubsection{Safety}


The decentralised control of large-scale systems poses a special challenge
for safety guarantees, as the local subsystem controllers have to ensure constraint satisfaction
despite only implicitly gaining information from the other subcontrollers, 
no direct communication channel being available, safety hence having to be enforced locally and independently.
While this tends to ensure a constant per-subsystem complexity, safety guarantees
extending beyond those decomposing into local requirements can only be met under restrictive assumptions. 
A common method~\cite{zhang2023data,hashemnezhad5371728safe} for achieving such guarantees is the 
use of neural networks projecting the proposed action onto the nearest safe one, the networks having been
trained on historical data to estimate the local impact of control actions on system states. 

Ultimately, research on safety for decentralised data-driven control remains limited.
The lack of communication fundamentally restricts the ability to guarantee global
safety properties in strongly coupled systems, making
decentralised safety mechanisms most appropriate
for settings with inherently local constraints.

\subsection{Distributed control}

%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108244&casa_token=VehPJM9m_hEAAAAA:3Bupc1FUPTPLgj8_M5IRi0bldulWFqXMWGRFIL9m9QTyk5ZJUKmMSrGcIH4sxvDlW5FZOeJIgs-2Ow


As opposed to decentralised control, subsystems in distributed architectures share information among system components.
This enhances the coordination capabilities of the agents, incurring improved scalability and robustness~\cite{ge2017distributed}. 
Factors that need to be considered in this design are communication delays and reliability. 

A general formulation of distributed control 
for a controller \(i\) would look as follows, where each controller uses its own state and state information shared by immediate
neighbours \(\mathcal{N}_i\), potentially transformed through a function \(\xi\):

\begin{equation}
u_i = \kappa_i(x_i, \{\xi(x_j) \mid j \in \mathcal{N}_i\})
\end{equation}

For linear settings and direct state propagation, this would reduce to:

\begin{equation}
u_i = K_{ii}x_i + \sum_{j\in\mathcal{N}_i}K_{ij}x_j
\end{equation}


\subsubsection{Distributed Model Predictive Control (DMPC)}

A family of techniques having been researched deeply for decades~\cite{SCATTOLINI2009723} is the collection of Distributed Model Predictive Control methods.
In a DMPC setting, each subsystem solves a local MPC and exchanges certain pieces of information, which is considered in addition to dynamics, constraints and objectives.
DMPC systems can be approached from a bottom-up or
a top-down perspective: 
either a collection of autonomous systems is considered, introducing communication
for coordination purposes, or from the
view of a monolithic system being decomposed into
subsystems, coordinated under constraints of
communication and processing power~\cite{maestre2014distributed}.

In non-iterative approaches, agents 
coordinate only once per sampling instant to solve
their optimisation problems, providing simple and fast coordination, albeit at the cost of sub-optimal performance~\cite{maestre2015comparison}.
Iterative DMPC strategies aim to 
overcome the sub-optimality of non-iterative
methods by repeatedly exchanging information until a
consensus or near-optimal solution is reached~\cite{wu2024iterative}. 
To realise this efficiently, decomposition techniques such as the alternating
direction method of multipliers~\cite{rostami2017admm}, the dual fast gradient method~\cite{wu2024iterative}
and Nesterov-accelerated gradient~\cite{8304602} approaches have been used successfully.

For computational and operational efficiency reasons, constraining the communication of subsystems to a local neighbourhood
can be advantageous. DLMPC~\cite{alonso2022distributed} and the corresponding data-driven formulation \(D^3\)LMPC~\cite{alonso2022data}
use the system level synthesis framework~\cite{anderson2019system} to generate a distributed model-predictive controller, which shares information only locally, the neighbourhood sizes being adjustable.
The system level synthesis framework parameterises the entire closed-loop system using two transfer matrices called system responses \(\{\Phi_x, \Phi_u\}\), such that 

\begin{equation}
\begin{pmatrix}x\\u\end{pmatrix} = \begin{pmatrix}\Phi_x\\\Phi_u\end{pmatrix}w
\end{equation}

\(w\) being the exogenous disturbance.

The data-driven formulation uses Hankel matrices to replace to closed-form system responses~\cite{xue2021data}.
DLMPC achieves the restriction of neighbourhood size, the maximum number of hops in the communication graph a subsystem can communicate with, 
through a locality constraint on the system response.
The data-driven DLMPC provides the same guarantees as the standard DLMPC, namely recursive feasibility, stability and convergence for both nominal and robust settings~\cite{alonso2023distributed}.

\subsubsection{Multi-Agent RL}

In Multi-Agent RL, each agent controls a subsystem 
and must learn policies in a partially observable environment while interacting with other agents.
As in model-based methods, centralised control via RL can grow intractable.
In a multi-agent network \(\mathcal{G}= (V,\mathcal{E})\)
each agent \(v_i\in V\) chooses an action \(u_i\in U_i\)
and communicates with neighbours along the edges \((i,j)\in \mathcal{E}\), 
receiving a global reward \(r(s,u)\). 
The joint action space \(U = \bigtimes U_i\) then grows too large to
efficiently control in a centralised fashion~\cite{chu2019multi}.

%The central assumption MARL in the context of Q-learning, the most common approach, 
%is the decomposability of the global Q-function, distributing each \(Q_i\) to the corresponding local agent~\cite{chu2019multi}:

%\begin{equation}
%Q(s,u) = \sum_{v_i \in V}Q_i(s,u)
%\end{equation}

A central distinction is to be made between 
centralised training with decentralised execution and decentralised training with
decentralised execution. 
In centralised training with decentralised execution, agents can freely communicate during the learning phase, which is performed by a centralised
algorithm. The policies are, however, executed in a decentralised fashion, agents communicating only via 
restricted channels~\cite{foerster2016learning}.
In decentralised training with decentralised execution, independent learners train policies without explicitly modeling other 
agents, which provides improved scalability~\cite{du2021survey}.


%https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10675394

\subsubsection{Event-triggered distributed control}

A key disadvantage of many distributed control approaches
is the necessity of high-frequency communication between the sub-controllers.
Solving this issue is the aim of event-triggered control, 
constructing trigger functions that 
communicate only when necessary~\cite{9354049}.
This can further be extended to a system where the local controllers
are deactivated, the control action held constant until a preset condition is met,
reducing computational burden~\cite{wang2020event}.

Each local controller continuously
monitors its state and transmits updates only
if a predefined triggering condition,
typically based on state error or
performance degradation, is violated~\cite{hirche2020distributed}.

One notable work by Yang et al.~\cite{yang2019adaptive} combined this with a reinforcement learning approach
developing a distributed
control scheme tailored to large-scale interconnected nonlinear systems
under uncertain couplings.
Each local subsystem implements an
adaptive-critic architecture to 
approximate its own optimal control
policy directly from collected state-input data.
The authors integrate experience replay, 
buffering past trajectories to accelerate learning
and stabilise convergence, 
and embed event-triggered communication to 
reduce inter-subsystem data exchange 
while still guaranteeing closed-loop stability. 
Crucially, the formulation accommodates
unknown subsystem interconnections by treating them
as disturbances while enforcing local
Lyapunov-based dwell and time-trigger
conditions to preserve global stability despite decentralisation.
The proposed method is a scalable data-driven algorithm
that yields stabilising controllers for each node
in the network with bounded communication and minimal
modeling assumptions.


Event-triggered data-driven distributed control has found application in a variety of areas.
Bu et al.~\cite{bu2025event} develop a data-driven control algorithm
for multimicrogrid interconnected systems with time delays, 
triggering communication only when the control error exceeds a tunable threshold,
proving convergence via Lyapunov theory.
Zhu et al.~\cite{10337762} propose a method for connected heterogeneous vehicle platoon control
considering sensor faults, network resource usage minimized through the effective use of triggering conditions.
Yu et al.~\cite{yu2023distributed} develop an iterative learning approach for the control of 
Multiple High-Speed Trains with switching topologies, proving 
stability and reduced bandwidth occupancy while retaining
sufficient performance.


\subsubsection{Robustness}

The key advantage distributed architectures have over decentralised ones with regard to robustness is the ability to explicitly
communicate among subsystems. While this allows for distributed robust control optimisation, it introduces the need for
more extensive performance considerations to scale to large-scale systems.  

In \cite{wang2024data}, robustness is achieved by explicitly modeling uncertainty on both subsystem
dynamics and interconnection terms, and embedding these uncertainty descriptions into a distributed
robust optimisation problem whose constraints are decomposed according to the network graph.
Rather than enforcing robustness independently at each node, 
tightened coupling constraints are coordinated across the network so that worst-case
uncertainty propagation is bounded at the system level. 
This graph-structured decomposition enables robustness guarantees that
scale with the degree of interconnection rather than the total number of subsystems,
making the approach especially applicable to sparse networks.

A robust distributed model-free controller is constructed in \cite{li2022robust}
for the domain of volt/VAR regulation over power distribution networks. 
Each local agent uses robust regression 
to mitigate bad measurement data
and iteratively updates its control strategy via a distributed alternating
direction method of multipliers algorithm enhanced with Nesterov acceleration, enabling scalability via
complexity growing approximately linearly with the number of direct connections at each subsystem. 
Efficient robustness is hence achieved via the model-free, data-driven feedback loop
which tolerates measurement errors and model mismatch,
the distributed optimisation architecture, where only limited peer exchange is required and
convergence is accelerated, and decentralised local correction at each node which ensures
the system stays robust to both local disturbance and coupling uncertainties.

Overall, robust distributed control for large-scale systems departs from classical robust
design by treating uncertainty as a network-level phenomenon rather
than simply a collection of independent local disturbances.
The reviewed methods demonstrate that scalability
depends on the exploitation of interconnection structure,
coordinating robustness margins across subsystems.


\subsubsection{Safety}

%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025385&casa_token=qjvIbDAx4-IAAAAA:M_4c8XzQjozwgwnYrNPirBtIXLgr0FI3ZlBIOL4bbFzo0MrfkKRA-L2I-HbvmhhS9Utle5M0ykQ&tag=1


Recent work in distributed control
emphasises certifiable safety through layered protocols
that ensure safe interaction among agents under
communication and dynamic coupling.

Khaledi et al.~\cite{khaledi2025data} constrain a direct data-driven distributed controller for multi-agent systems
via CBFs incorporating quadratic programming optimisations. 
The online computational complexity is dominated by the interior-point quadratic programming problem, which is, for \(m_i\) being the control input
dimension for agent \(i\), \(\mathcal{O}((\sum_im_i)^3)\) due to the factorization of
the Karush-Kuhn-Tucker system for dense data~\cite{ye1989extension}.
As a result, this approach is primarily suited to moderately sized networks,
highlighting a fundamental limitation of CBF-based safety mechanisms
whose safety constraints are enforced through globally coupled online optimisation problems 
when applied to large-scale systems.

In contrast, the Trajectory-Tube Distributed Explicit Reference Governor proposed in \cite{convens2022safe} explicitly targets scalability by decoupling safety enforcement across agents through predictive safety tubes that account for higher-order nonlinear dynamics and inter-agent coupling.
Safety information is exchanged only locally among neighbouring agents, preventing the
propagation of global constraints and enabling safety certificates whose complexity
remains bounded as the swarm size increases. 
This structural localisation of safety guarantees allows the method
to scale to large, resource-constrained UAV swarms while maintaining 
constraint satisfaction under limited communication.

While research on safety in distributed data-driven control architectures remains limited,
the presented 
methods suggest that safety guarantees in large-scale systems are feasible primarily
through spatial localisation. 
Approaches that prevent the global coupling of safety constraints and bound per-agent computation and communication
hence seem to be more promising for large-scale system scenarios.


%\cite{shaham2024learning} presents a safe distributed certifiably stable neural network controller  for heterogeneous platoon control.


\subsection{Hierarchical control}

% A Data-driven Hierarchical Control Structure for Systems with Uncertainty

In hierarchical control scenarios, the control structure is conceptually arranged in multiple levels.
The higher level controllers coordinate the actions of the lower level ones, 
being responsible for meeting the overall goal of the large-scale system~\cite{SCATTOLINI2009723}.
Hierarchical control could be viewed as a special case of distributed control, 
where some controllers take on special coordination roles.

This paradigm allows coordination of complex large-scale systems 
by assigning high-level layers to strategic, long-horizon decisions
and lower-level layers to fast, local actuation.
The approach mitigates the curse of dimensionality
inherent in centralised optimisation and can improve robustness
and scalability compared to purely distributed schemes~\cite{SCATTOLINI2009723}.

\subsubsection{Architectural principles}

A canonical three-layer hierarchy distinguishes between:

\begin{itemize}
\item Supervisory layer (Level 1): Performs system-wide coordination, optimisation, and constraint management. It determines global references or resource allocations for subordinate controllers.
\item Coordination layer (Level 2): Translates supervisory commands into feasible sub-objectives for each subsystem, handling coupling constraints and communication among local controllers.
\item Local control layer (Level 3): Executes low-level control laws (e.g., MPC, RL, PID) to track references or regulate states under real-time constraints.
\end{itemize}



This division of control responsibility originates
from industrial process control~\cite{terry1983hierarchical} %double check this
and has since
been generalized for power systems~\cite{vasquez2010hierarchical},
transportation networks~\cite{10667672}, and multi-robot systems~\cite{ju2021hybrid}.
The separation enables each layer to operate at different
sampling rates, leading to computational tractability and
improved modularity~\cite{maestre2014distributed}.

\subsubsection{Data-driven hierarchical model predictive control}

Hierarchical Model Predictive Control extends MPC to a multi-level framework, where upper layers solve relaxed or aggregated optimisation problems whose 
outputs guide lower layers~\cite{SCATTOLINI2009723}. 

Shi et al.~\cite{shi2020data} present an indirect data-driven hierarchical control structure for systems operating under uncertainty.
The controller lower in the hierarchy identifies a linear approximation between the higher-level signals and output, whereas the higher-level controller component  
has the task of dealing with the modeling errors and environment uncertainties.

As for direct data-driven methods, model-free
formulations such as hierarchical DeePC have emerged~\cite{10667672}, demonstrating
such a structure for autonomous mobility-on-demand fleets: the upper layer optimises
global vehicle repositioning and the lower layer applies local DeePC to individual agents.


\subsubsection{Reinforcement Learning}

One of the early papers in the field of hierarchical reinforcement learning was \cite{singh1992transfer},
proposes a technique of decomposing tasks, solving them individually using Q-modules and sharing solutions across multiple composite tasks,
laying the groundwork for the widely successful hierarchical reinforcement learning framework. 

% defintiion for HRL https://arxiv.org/pdf/2011.04752

Formally, given a high-level controller \(Q_1\) declaring the subgoal \(g\) and the lower-level controller \(Q_2\) generating the corresponding action \(a\),
hierarchical reinforcement learning can be expressed as follows~\cite{naveed2021trajectory}, where \(Y\) denotes the Bellman Target:

\begin{equation}
Y_t^{Q^1} = \sum_{t'=t+1}^{t+1+N} R_{t'} + \gamma \max_g(s_{t+1+N},g)
\end{equation}

\begin{equation}
Y_t^{Q^2} = R_{t+1} + \gamma \max_aQ(s_{t+1}, a| g)
\end{equation}


Applying hierarchical reinforcement learning naively to large-scale systems can lead to computational inefficiency and convergence difficulties due to the inherent challenge of a high-dimensional action space,
leading to a trend towards combining hierarchical and distributed reinforcement learning, intending to reduce task complexity and accelerate training speeds.
One such work is \cite{chen2023distributed}, a distributed hierarchical controller using deep reinforcement learning.
The authors develop a new framework, coined hierarchical reduction reinforcement learning,
addressing the critical challenge of computational inefficiency in deep reinforcement learning for large-scale power grid emergency control.
Hierarchical reduction reinforcement learning is based on a two-layer hierarchical decomposition that achieves efficient and accurate action space reduction via a self-supervised learning algorithm. 
By training a top layer to identify a small effective action space,
it significantly reduces the control complexity for the bottom layer.
Furthermore, an experiences-sharing-based distributed architecture is integrated
to enable parallel training and enhance scalability. 
This approach substantially improves upon prior art in convergence speed,
solution quality, training robustness, and adaptability to large-scale systems.

% MFAC is not reinforcement learning :/
%To more efficiently handle non-linearities, \cite{deng2025extended} 
%proposes a hierarchical control scheme for  
%multi-agent systems that combines partial dynamic linearization 
%with an extended state observer (ESO). 
%A distributed estimator 
%that generates per-agent reference trajectories while
%explicitly handling communication delays is constructed for the high-level control.
%At the lower layer, each agent's nonlinear, 
%non-affine dynamics are reformulated into an affine 
%form that separates a linear input gain
%from all unmodeled nonlinearities. 
%Those nonlinear leftovers are treated as an extended state
%and estimated by a linear ESO, while the input gain is
%updated via an adaptive law.
%Bounded tracking error are proved using Lyapunov
%and Halanay-type delay arguments and improved tracking
%and more stable coordination compared to prior approaches are shown via simulations. 




\subsubsection{Robustness}

Hierarchical control provides a structured mechanism for achieving robustness in complex systems by separating 
decision-making across layers with distinct time scales and uncertainty characteristics.
Rather than enforcing robustness uniformly, hierarchical architectures might confine learning-induced uncertainty and model mismatch to higher layers, 
while lower layers enforce stability and disturbance rejection, often employing different control methods at each layer.
This principle is frequently exploited in robust reinforcement learning architectures, where robustness is achieved by restricting learning to supervisory roles~\cite{li2020learning,naveed2021trajectory}.

In the domain of hierarchical control for networked physical systems,
the work by Nandakumar et al.~\cite{nandakumar2024enhancing} demonstrates a data-driven
predictive droop-control architecture structured hierarchically
applied to islanded microgrids. 
The high-level module uses a physics-informed sparse identification
prediction model and model predictive control to issue
set-points for frequency regulation,
while the droop control at the lower level tracks those
references and compensates disturbances. 
Reachability analysis is employed to bound worst-case deviations, 
thereby contributing robustness guarantees
under modeling uncertainty and disturbance.
Robustness is achieved through 
adaptive model refinement and time-scale separation, 
the upper layer continuously re-identifying system dynamics,
while the lower predictive droop layer enforces
bounded invariance through reachability-based compensation.


Overall, the deliberate separation of uncertainty handling across layers emerges as a key mechanism for achieving robustness in hierarchical control architectures. 
This structural containment seems particularly critical in large-scale networked systems, 
where it preserves computational scalability by confining expensive optimisation and adaptation to
supervisory layers while allowing local controllers to focus on fast stabilization and disturbance rejection. 
While existing work on robustness in large-scale hierarchical systems remains limited,
the presented results indicate that hierarchical separation offers a promising and scalable pathway for robust data-driven control.

\subsubsection{Safety}

Hierarchical control architectures offer a natural mechanism for enforcing safety in large-scale systems by exploiting abstraction and time-scale separation, thereby distributing safety responsibilities across layers with bounded complexity and dimensionality. Crucially, safety constraints are enforced on low-dimensional abstractions at higher layers and on local state variables at lower layers, avoiding globally coupled safety verification.

A representative example is presented by Ahmad et al.~\cite{ahmad2025hierarchical}, addressing
scalability for safe multi-agent reinforcement learning by decoupling coordination from safety enforcement.
A high-level policy learns joint cooperative behaviour, while low-level controllers enforce individual safety via CBFs.
Safety-critical quadratic programs are solved only at the agent level and depend solely on local state
and interaction neighbourhoods, keeping per-agent
computational complexity independent of the total number of agents.
This approach achieves near-perfect safety rates in dense, conflicting road networks.

In a predictive control setting, Vallon et al.~\cite{vallon2022data} propose a hierarchical, data-driven architecture for unknown operational environments.
Offline trajectory data is mined to construct a library of recursively feasible terminal sets and safe equilibria. The supervisory layer selects target states from this library, effectively decomposing the global environment into a sequence of locally reachable, data-validated safe regions.
The local MPC problems can then handle the local constraints in parallel, 
while the high-level hierarchy manages the global topology through a sparse set of historical safe states,
providing scalability to a large number of subsystems.

%\subsection{Higher Level Control}
%
%
%While most data-driven control efforts for 
%large-scale systems focus on the microscopic 
%level of node control, there is increasing 
%recognition that higher levels of abstraction 
%can provide leverage for scalability and robustness. 
%Specifically, edge control and structural control 
%have emerged as two promising approaches to orchestrating 
%collective behaviour in complex systems~\cite{ControllingComplexSystem}. 
%These approaches shift attention from 
%direct state manipulation of individual nodes to 
%the design of interactions and the adaptation 
%of system topology, providing a macroscopic handle 
%on global dynamics.


%\subsubsection{Consensus/synchronization controllers and distributed optimisation}

%\subsubsection{Event-triggered and sampled/quantized coordination}




%\section{Safety \& Certification at Scale}

%A continuing challenge in the field of data-driven control remains the question of verifyable safety.
%In many application areas of control theory, guarantees are required for methods to have any use at all.




%\subsection{Stability \& Robustness}
%
%Stability refers to the system's ability to remain bounded 
%and to return to equilibrium after small perturbations. 
%Formally, a system \(\dot{x} = f_u(x) , x \in \mathcal{X}\)
%is stable at its equilibrium point \(x_e\in \mathcal{X}\)
%if 
%\begin{equation}
%\forall \epsilon > 0 \exists \delta_\epsilon \forall t: ||x(0) - x_e||_2 < \delta_\epsilon
%\implies ||(x(t)-x_e)||_2 < \epsilon
%\end{equation}
%
%There are, among others, similar notions of asymptotical and exponential stability~\cite{min2023data}.
%
%
%
%\subsubsection{Lyapunov approaches}
%
%Lyapunov theory is one of the most popular techniques to
%analyse stability of control systems~\cite{li2023survey}.
%
%%Especially suited for large-scale systems is the composite Lyapunov function method,
%%using a composite Lyapunov function constructed as a weighted sum of isolated subsystems' Lyapunov functions.
%%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106217
%
%Min et al.~\cite{min2023data} propose Control with Inherent Lyapunov Stability (CoILS), a technique that 
%jointly learns a controlled dynamical
%systems model and a feedback controller from data.
%The key innovation is that the model is guaranteed by construction to
%be stabilized in closed-loop with the learned controller.
%This is achieved by constraining the open-loop dynamics onto the 
%subspace of dynamics stabilizable in closed-loop by
%the learned controller through the concurrent learning of a  parametric Lyapunov function,
%leading to the inherent guarantee of exponential stability of
%the learned models.
%
%%While Lyapunov-based approaches such as CoILS 
%%enable provable stability for small and medium-scale
%%systems, scalability to large-scale interconnected
%%systems remains an open frontier. Data-driven
%%large-scale control must address coupled uncertainties,
%%distributed dynamics, and limited data per subsystem, all of which complicate robustness guarantees.
%%
%%A promising research direction is distributed and compositional Lyapunov analysis. 
%%Instead of deriving a global Lyapunov function, 
%%each subsystem learns a local Lyapunov function 
%%\(V_i(x_i)\) from data, 
%%with interconnection terms bounded via 
%%data-driven estimates of subsystem coupling. 
%%This leads to scalable, certifiable guarantees.
%%Such approaches scale linearly in the number of
%%subsystems and are compatible with
%%decentralized DeePC or multi-agent RL controllers.
%%
%%Lavaei et al. [2] developed a data-driven
%%dissipativity framework for compositional
%%safety verification of interconnected systems:
%%local storage functions are identified from trajectory data and
%%composed to certify global dissipativity.
%%These techniques scale linearly with the number of
%%subsystems and naturally exploit system sparsity.
%
%\subsubsection{Contraction Theory}
%
%
%

%e based on a receding-horizon open-loop optimal control problem, which is guaranteed to be solvable
%and ensures constraint satisfaction at every control sampling time step. 



%\begin{figure}[h]
%\begin{center}
%\includegraphics{./images/grins.pdf}
%\end{center}
%\caption{A vector graphic loaded from a PDF file}
%\label{Pic1}
%\end{figure}

%\begin{figure}[h]
%\begin{center}
%\includegraphics{./images/grins.png}
%\end{center}
%\caption{A bitmap graphic loaded from a PNG file}
%\label{Pic2}
%\end{figure}


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results.}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



\section{Conclusion}\label{conclusion}


Data-driven control has become a central tool for addressing the scalability and modeling challenges inherent 
to large-scale dynamical systems. 
By shifting the emphasis from first-principles modeling to information extracted directly from data,
these methods enable control designs that would be infeasible with traditional approaches alone.
This survey reviewed the main paradigms in data-driven control, spanning data-driven modeling,
direct model-free control, and the architectural choices required to deploy such methods at scale.

A recurring theme across the literature is that scalability is
rarely achieved by a single algorithmic idea. 
Instead, practical large-scale control solutions combine dimensionality
reduction, structural decomposition, and appropriate control architectures such as decentralised, distributed, or hierarchical schemes. 
While data-driven methods can significantly reduce modeling effort and
improve flexibility, they introduce new challenges related to data quality, computational complexity, and performance guarantees.

Despite substantial progress, several open problems remain.
These primarily include the exploitation of large-scale structure for robust and safe controllers in networked systems.
Research in all presented control architectures remains limited and commonly tends to employ standard
mechanisms in subsystems. Novel safety approaches leveraging structure to provide guarantees not easily decomposable scaling to large systems
could be the topic of future investigation.
Further, security aspects, such as malicious agents or subsystems, or the tampering with the learned-from data, are seldom considered.
Addressing these challenges will be critical for moving data-driven control toward broadly applicable, reliable solutions for real-world large-scale systems.

% conference papers do not normally have an appendix


% use section* for acknowledgement
% \section*{Acknowledgment}
% The authors would like to thank...





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}



% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\printbibliography

%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}




% that's all folks
\end{document}





% Hankel matrix, Willem's lemma
% notation wise: explicitly show same