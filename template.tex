%% bare_conf.tex
%% V1.4
%% 2012/12/27
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/
%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex,
%%                    bare_jrnl_transmag.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[conference]{IEEEtran}
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}



% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% For directly writing german umlauts uncomment the appropriate line for
% your operating system:
% Windows:
% \usepackage[ansinew]{inputenc}
% Linux:
\usepackage[latin1]{inputenc}
% Mac
% \usepackage[applemac]{inputenc}
% If none of the above lines work you can also try the following:
% \usepackage[utf8]{inputenc}



% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{cleveref}

% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% add custom packages
\usepackage{color}
\definecolor{tumblue}{rgb}{0, 0.4, 0.74}

\usepackage[backend=biber,  style=ieee, url=false,doi=false, isbn=false, citestyle=numeric-comp]{biblatex}
\addbibresource{references.bib}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}

% Add the seminar's cover page
\input{coverpage}

%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
\title{Data-Driven Control for Large-Scale Systems: \\ A Survey}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Dominik M. Weber}
\IEEEauthorblockA{Technical University of Munich\\
Email: dominik.m.weber@tum.de}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}



% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
Large-scale dynamical systems pose fundamental challenges for classical control due to high 
dimensionality and modeling complexity.
Data-driven control offers an alternative by using measured data instead
of relying on first-principles models.
This survey reviews data-driven control methods for
large-scale systems, covering both data-driven modeling techniques and direct model-free approaches.
The control architectures of decentralized, distributed, and hierarchical control are discussed
with a focus on enabling scalability to large scale systems.
The survey highlights the state of the art in
applying data-driven approaches to large-scale sytems, including trade-offs and open research challenges.


\end{abstract}

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}\label{introduction}

%https://pdf.sciencedirectassets.com/791905/AIP/1-s2.0-S3050744825000106/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIEz4%2B%2Fkg9Y5%2FYfr7WeX1j8hZzSBIxjzt%2F%2Fap0%2FUOg3WEAiEA4aYwbCOiunuCF06Ku81ibq2LB27GQopCbdVd6TbNqaoqsgUIfhAFGgwwNTkwMDM1NDY4NjUiDGYg1FEumCZ7KGm%2BQiqPBd7779jTpyZpw3qHgX1UfChGnifRyLmU6Gx758auDRTE1lfE7xkFXShjmgEgD%2B4L1j0AZX%2BAqNv9iCAs1ufDJhpwuvn0MvJJsZWO%2Bam59GIjw9frUa8n0tpkEq9DPt%2F1L1XJJGTquEohPSaxpOMf7KenCa58IIs59L3erXOdaJR590sBMZeOcnKShlaUflkdmThvBHGS4Qrh6XaOg9phH2N0TU%2BReFbEqoslLTXLrogoGMGnBofRtSbwWL2PXHz7peR9WZLF10xHnmuXaxBm2lEtcznFlPp9okAIRlG8dtUcdmjrJoosewBxcwmY%2BrVGKIWOJJQLY%2BDXRSRHxVX7EMwaL%2FNRkjgjN3tHI9K7jsnMDR0iCT5L4ww6uq9CYs4%2FSQPynvWuxfCHYspPCt1o%2By79AgrTLFINXJj2bocRxPU5%2BZoKIHtXTahwp0XpSU078%2FkVGTTLalzlOi8Bs4NZOdQyFihoLwxvw7FOO7bN4tTCQp9h5wjh0WzLxo3lpSGenZL7qWctaEJ67RRQlfsJHnetBTFWDarmnUyvtIz2M5H92e%2FE6yGo4Bu1BfIx%2Bodbyfoe46H%2BdpzfUd8NwWsuSeWSL5NblSq6zjo8B1go44W65rAIjbtrjmqs%2BFeCWJ0lEvEnbJpf8E7rqkjHOGUgpiXZv2FVHlDlLnIjakhGLfa%2ByWc%2FFqHnZCKtDZkA%2FQMQ8LNaIsH1YYPDaWHD00otZO2kC3YEQQQM2emRBsS8sPMmyMhEja2QVL3NtPt8LsPTuzoT2DB7PNVMS9%2B1qli9wgvXaAEbCJjVi9aodbHXJuEmundCS%2FKKnMQYy%2Fv28nM4EBQlt%2Bd8pC0oMGt4tPB0jhzuohzvd4dpr6egxmddlbgw2PPhyAY6sQHDSwSxUhMSCj5VuxEUEG1UxwonZ2FwzcfGx%2FHBwqoFOiAhAXTQ3QuZIuK0jvjaEGv9A8OSwb8fed8PKnPAPu%2Fm4aBv6pNUrQ9YgJBG3LnwhFeAOt%2FPTG7uBGwM8DDrh5Q4iRX%2BpQK%2BIVixdTF7diwZBEi97rJEJxHHYxSr%2Bh8dNkHXFVckNU2YqyBYx8bCdIaqWXEHMRkTinweb1QKBhGvele3avTo0B7h4yosoFNcYDc%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251115T133547Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYUDP3E2MG%2F20251115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7c858a985fd1ace403ab7d9dd6fecf198999ddf5aa63f02e2cd87e3b4f70cd82&hash=e7d7780dacefe8dec9e39cada7c3e505326ce01c09b4833e54846d2ff3637589&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S3050744825000106&tid=spdf-6398be90-0a83-4ff8-8643-f0e0edb80f3f&sid=d24a09c8193a7449834b42f3eb10962b751egxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1e035f5d070552545056&rr=99ef22439c1203b8&cc=de&kca=eyJrZXkiOiJQdytLUUt5amQ0VTlHdjRwK1pvcENpeVF0QVllZjFKdHZaSGFaZDN4R05MRk42ekwxRTV4ZWZPMWNpNFhaT2tkeWhFZ2ViVDc0OFJubTQzKzlvMDJMTWFvOExUN2tqQ2VmM3Q5RGwwN2pvUk5zMUJ1dmFZSWRDckthRUhGdk5NUmNlV3haRzh6Z21GaExzMGJCb3RmQ3ExYzJkQXZMd01UYnFLaVdJaWV5ME4xVjZYUm82TT0iLCJpdiI6IjFjYWNiYTQ5NDc4NWJlZjM0ODE2MjUyMGE4MzgzOGJjIn0=_1763213765135

Large-scale dynamical systems arise in a wide range of application domains, including power and energy networks, transportation systems, industrial processes, and multi-agent robotic systems~\cite{kordestani2021recent}. 
Their defining characteristics, including high dimensionality, strong interconnections, and heterogeneous
dynamics, render classical centralized control approaches difficult to model,
computationally intractable, or insufficiently flexible.
As system complexity grows, deriving accurate first-principles models 
designing controllers around them becomes increasingly costly and error-prone~\cite{DDC_Overview}.

Data-driven control has emerged as a promising solution to some of these limitations. 
Instead of relying on explicit physical modeling, data-driven approaches exploit measured
system trajectories to infer models or synthesize controllers directly. 
This shift has enabled control designs for systems where traditional modeling is infeasible
or where operating conditions change over time~\cite{behavioralDataDrivenControl}.
However, the applicability of data-driven methods to large-scale systems is not solely determined by learning algorithms alone.
Scalability hinges on how systems are decomposed, how information is exchanged, and how control decisions are coordinated across subsystems~\cite{ma2024efficient}.

While the literature on data-driven control is extensive, its interplay with large-scale sytsem control scenarios has received 
less focus. Conversely, research on large-scale control architectures often assumes access to accurate models and does
not fully account for model uncertainties and difficulties for obtaining such models in real-world settings~\cite{xia2024predictor, aljohani2024tri, ma2024cloud}.
This survey aims to provide a structured overview of data-driven control for large-scale systems, emphasizing how modeling choices, control paradigms, 
and architectural design jointly determine scalability. 
It highlights trade-offs between indirect and direct data-driven control, 
centralized and non-centralized architectures, and modeling fidelity versus computational tractability.

The remainder of the survey is organized as follows. 
Section \ref{background} provides a brief background on data-driven control, large-scale systems and safety filters, the central
technique for providing formal guarantees for data-driven controllers.
Following is an introduction to direct and indirect data-driven control techniques, forming the basis for
large-scale deployment in non-centralised architectures.
Section \ref{modeling} reviews data-driven modeling techniques relevant to large-scale systems, enabling system decomposition and dimensionality reduction. 
Section \ref{modelfree} covers direct, model-free control approaches and their extensions to large-scale and distributed settings. 
Section \ref{architecture} discusses decentralized, distributed, and hierarchical control architectures, analyzing how architectural choices affect scalability, 
coordination, and performance. Safety and robustness mechanisms are introduced focusing on aspects necessitated by the system's scale.
Section \ref{conclusion} concludes with a brief discussion of open challenges and directions for future research.


\section{Background}\label{background}

% no \IEEEPARstart
\subsection{Data-Driven Control}



Traditional control approaches largely followed the strategy of first deriving a model
from first principles and afterwards building a controller upon it. 
%A premier example of such an approach is MPC, model predictive control.
Such model-based control can become intractible or inaccurate for complex large-scale systems, though~\cite{DDC_Overview}.
%\subsubsection{Classification}
A fundamental delimination in data-driven control can be made between direct and indirect approaches. 
In indirect methods, a model is learned from data - a process termed system identification (SI) - and, as in traditional control, a controller built upon it.
%Examples of techniques using this strategy are Koopman-theory~\cite{Korda_2018} and Gaussian process~\cite{Kocijan01122005} based approaches.
In direct data-driven control, the dynamics of the system are treated as a black box and the controller is directly built from the data~\cite{DDC_Overview}.



%\subsubsection{Advantages}

Data-driven approaches provide a range of benefits compared to traditional model-based ones. 
System identification, the basis for indirect data-driven methods, has
the key advantage of being generally applicable and to large degrees automated, 
whereas a model-based technique requires expert-knowledge for deriving the model from first principles,
the specific result then being domain-specific. SI further provides the practitioner with 
tools to fine-tune the accuracy required, as complexity tends to rise with more accurate models~\cite{behavioralDataDrivenControl}.


%\subsubsection{Disadvantages}

Despite their benefits, data-driven control methods 
face several limitations. 
A central challenge is the heavy reliance on the 
quality and quantity of available data, insufficient or 
noisy datasets having the potential to significantly 
degrade the performance of the resulting controller~\cite{HOU20133}.
%Further, data-driven methods often come with high computational 
%demands, both in terms of learning and real-time operation, 
%which limits their deployment in safety-critical 
%or resource-constrained systems [6]. 
Another drawback is the lack of interpretability and 
transparency compared to physics-based models. 
First-principles models typically allow direct 
insight into the mechanisms driving system behavior, 
black-box controllers derived purely from data can be 
difficult to analyze or verify~\cite{Brunton_Kutz_2022}. 
Finally, issues of robustness and generalization remain 
open problems, as controllers trained on one operational 
regime may fail to extrapolate reliably to unseen 
conditions~\cite{ramadan2025floodgatescontaindeepclimit}.

%For large and complex systems, automatic system identification hence   

\subsection{Large-Scale Systems}


Large-Scale Systems do not have a single clear definition.
The term is rather used whenever a system grows unweildly to control with traditional strategies.
It is further often used synonymously with complex system, a system consisting of multiple interacting units 
that exhibits emergent collective behavior which is not the simple summation of its parts~\cite{ControllingComplexSystem}.
% a system is considered as large scale complex whenever it is necessary to partition the given analysis or synthesis problem in order to come up with manageable subproblems
% https://pdf.sciencedirectassets.com/271897/1-s2.0-S1367578812X00026/1-s2.0-S1367578812000028/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDkaCXVzLWVhc3QtMSJGMEQCIFuyO2%2BOyv4oEbvlBReZXR12ei9IPZCW5zmPtdWgH3yKAiA9tGSvndkFQW4ktFpVnS7Qsqax0atoQRMRT95WTdkIZSq8BQjS%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMyC1wWjnrzaLee3m0KpAFWle6d2mOWXDum5AbJS67M%2BWWoPU5UwcCWNSgG1A4QurSwIMb4XcK%2FVAoWp%2Fez8tKQYpXc4iOecz8GlSMVK6EwDgAlExE7FEUiwHADa0mCyVxIRqQBuu4Dspt8jo7jGff1lkClIHVULoVR5HLXhw3%2B7wdV9Udtugea3i2Gojl%2FYGhyPoIlG3iKwNDnZKlZ76l06Kf%2BCxxqYbxkEi0%2Fkl%2F2YAtYdIv6cCAcDAQ3%2FM9wfY%2FSlMFnWKMiT5j6%2B3hAYWLn9Mkd5FoKcxQVzgWxwGTHbgXea9rtTbCHMgr5lnI9%2FdwhFOoDkeqaajGEd%2B8IbHRWmrcRUhN%2Bwc9IBNrYjneCmHx2rIMUSK5ErSqVixAWjw3WNdy%2BPQ5MoPCBjUi62BrQrtVAEfXbD%2FSyWfQuPPYXV7lJW9n%2BYGlx3laPojmCvif5VkJR%2BnPSD1ucw9lP70YEpsAgQr44ZoHmjxXp%2FaX0HJhDWERE%2BhYnQ2%2Fif6uDi3oQSl%2BJYHsC4LWxA75k1j2tCA%2B6X%2FTZzwLmIJqLVMdZH13lrIWoKvzBgruvo6haPj2O%2FWggr7YA6jBJNZ8lS5%2FZJL1q%2BgDYEQK%2FDZSin0XI9uNCD%2Bwhsg84qOJTBA2c%2BdKg7bV0S2t44rbrggC04ey8G%2Fg7zstch2h4l1bAmyNyGiwREnYoiZrE%2FKAzYoNNwK0rR9ejPQzu4WZ9hOcBSi98bQnQqbKuDLTR0xLRpqysqr0S6x0TTn2caVpnWATs5Nkc6mg0hwPeEPfTB%2B%2BEoFdu4wzgjP4Y9csvFWjLqgnxNyc3TtJ0y9db8URTV5m1QGII4%2FqUt1uf9MrJOmIj%2FG%2BrZzRx%2FZAwFB2cLDAazzZ0jhqdGmK08eHqxr4guwcfXAwoPOdxwY6sgEmFF1uMvj97RYxU1%2BbQXqJ4PBHdjI7J8%2B0pQSDELzqI4m2uYZ4n6b82bkqzp3aIxqTq8Pgo00jqnQdExaet83PyoVP7GeAxYPSyR4P7qTavpW%2BbF1otVHaGCsiKYwuBQYmqB0DVd4UIIPNgkXfVznTG0xY7cdL0c%2FPwc3xpNJO1Km9HSo615oRUSryJ1cULVsw%2BUpaasuWPwogTUiVP1bIGVDEkM8dI9KlFNGxeltS6%2BjI&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251009T093726Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQS55SIAW%2F20251009%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=6a6ac8d15b5cb6434913e9415a4b20dadbcab6e2e795f0a35a4424128e3a6b70&hash=c75fc87a3e3b7ed67b7f7e226f8bec06b27f3feb422145c63f846f91f5658e16&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1367578812000028&tid=spdf-063f0f87-4e00-43a6-b7ff-10f6f3764c08&sid=029b8ee71b7c5841003ae926bfe04b1834bagxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1e075d5907000a58510c&rr=98bce63c6fd7974a&cc=de
Application domains of large-scale system control are areas such as power generation and distribution, traffic and water networks, and industrial system processes, such as heating ventilation or supply chain management systems~\cite{kordestani2021recent}.


The central problem in controlling such systems is the scalability requirements they impose upon the controller, often reaching thousands of interacting entities~\cite{ControllingComplexSystem}.
Traditional first-principle-based control of such systems can be intractable to formulate and compute, while being sensitive to uncertainty~\cite{YU2025126253}, motivating the usage of data-driven methods.
Generally, techniques used to handle control of large-scale and complex systems include
reducing the model to a more tractable size through model order reduction methods,
utilising non-centralised control architectures and including 
communication protocols and interconnects between individual subsystems into the control model.  

%It has been shown that by imposing locality or separability, 
%many large optimal control problems decompose into parallel local %subproblems whose complexity does not grow with the total system size, 
%using techniques such as system-level %synthesis~\cite{wang2017separablelocalizedlevelsynthesis}.



Model Order Reduction methods tackle the problem of reducing the complexity of large-scale systems.
This technique attempts to generate reduced models reproducing the input-output behavior 
of large-scale systems accurately enough for the desired use-case.
Traditional model reduction methods fall into two categories: Singular Value Decomposition (SVD)-based and moment matching methods.
SVD-based techniques are related to the eponymous singular value decomposition.
Their core idea is the computation of controllability and observability 
Gramians, eliminating hard-to-reach and -observe states~\cite{lowenerIntro}. 
Their advantages include the preservation of stability and a computable error bound. 
While work is being done to make them more efficient using approximations \cite{numSolutionLargeScale, prajapati2022model}, their resource requirements
remain their main drawback~\cite{lowenerIntro}. A popular method in this class of model order reduction techniques is Balanced truncation (BT)~\cite{balancedtruncationOriginal}.
Moment matching methods consider the problem of matching the coefficients of power
series expansions of the transfer function at selected points, reducing model reduction
to rational interpolation. They tend to be cheaper to compute than SVD-based methods, 
but do not provide as strong of theoretical guarantees, the preservation of properties depending on factors such as the choice of expansion points~\cite{ANTOULAS200419}.
A prominent example are Krylov subspace methods~\cite{freund2003model}.

%This distinction does not necessarily apply to the techniques themselves, though, but rather to their
%implementation. 

The second key approach taken to enable the control of large-scale sytems is the decomposition of the centralised
control problem into smaller, more manageable control-tasks distributed to sub-controllers.
A centralised controller often does not suffice for effectively controlling large 
scale systems, the necessity of multiple controllers even being part of some definitions of large-scale sytems~\cite{kordestani2021recent}. 
Depending on the interaction between the controllers, such approaches can
be categorised into decentralised, distributed and hierarchical control architectures, in addition to hybrids thereof~\cite{kordestani2021recent}.

Control of large-scale sytems taken can roughly be categorised into three distinct levels: node control, edge control and structural control~\cite{ControllingComplexSystem}.
Node control concerns itself with the immediate determination of dynamics of a subset of agents at the lowest, microscopic view.
Edge control works by dynamically adjusting the communication protocol between the individual agents.
In structural control, the network topology can be reshaped in order to guide behaviour at the macroscopic level.
Most works are concerned with node control, as this resembles the traditional single, small-system control the closest.
While not all layers might be controllable for a specific use-case, such as the network topology being fixed and unchangeable, the best results are usually achieved when considering all levels~\cite{ControllingComplexSystem}.

\subsection{Safety filters}

%\subsection{Safety \& Certification}

The inherent complexity of large-scale systems not only
challenges tractability but also exacerbates
safety and certification concerns.
As data-driven controllers replace interpretable physics-based models,
formal guarantees must often be reintroduced. 
This section serves as an introduction to safety filters,
a popular approach for achieving formal guarantees in data-driven large-scale systems~\cite{zhang2023data, ahmad2025hierarchical,khaledi2025data}. 

A system \(\dot{x}(t)  = f(x(t), u(t))\) is called safe if 

\begin{equation}
\forall t\in \mathbb{R}_{\geq 0} x(t) \in \mathcal{X} \land u(t) \in \mathcal{U}
\end{equation}

where \(\mathcal{X}\) and \(\mathcal{U}\) are the state constraint set and the input constraint set, respectively~\cite{10266799}.

Unlike traditional model-based designs, 
learning-driven controllers must operate under 
epistemic uncertainty arising from limited data, 
unmodeled dynamics, and distributional drift. 
Consequently, a major strand of recent work focuses on 
safety filters. These filters are supervisory mechanisms that ensure system 
trajectories remain within a certified safe set, 
even when the underlying controller or policy is learned. Formally, a safety filter 
is a function \(\kappa: \mathbb{R}^{n_x}\times \mathbb{R}^{n_u}\to \mathcal{U}\)
which transforms the control signal (\(u(t) = \kappa(x(t), u_{contr}(t))\)) determined by the controller \(u_{contr}\)
such that safety constraints are respected, and the modification is minimal, i.e. minimising 

\begin{equation}
\int_{0}^\infty||\kappa(x(t),u_{contr}(t))-u_{contr}(t)||dt
\end{equation}

Among these, three major methodological families 
dominate current research: Control Barrier Function (CBF) 
approaches, Hamilton-Jacobi reachability-based methods, and Predictive control 
formulations~\cite{10266799}.

%\subsubsection{Control barrier function (CBF) approaches}


For a known control affine system \(\dot{x} = f(x)  + g(t)u\), a 
Control Barrier Function can be defined as follows~\cite{jin2023robust}: 
a continuously differentiable function \(h: \mathcal{X} \to \mathbb{R}\) 
is a CBR if there exists an  extended class \(K_\infty\) function \(\alpha\):
\begin{equation}
\sup_{u\in \mathcal{U}} \dot{h}(x,u)\geq -\alpha(h(x))
\end{equation}

for all \(x\in\mathcal{X}\) where \(\dot{h}(x, u) = \nabla h(x)
f(x) + \nabla h(x) g(x)u\).

The key idea is that for the safety set \(S = \{x \in \mathcal{X} | \exists u \in \mathcal{U} \land h(x) \geq 0\}\),
any Lipschitz continuous controller \(u(t)\) is safe~\cite{ames2016control}.
While CBFs traditionally rely on explicit system models, recent research
has proven the viability of learning them from data as well~\cite{wang2022data,bajelani2025data}.


Hamilton-Jacobi reachability analysis computes the backward reachable tube, a collection of all initial states with trajectories eventually reaching a target set even under the worst-case disturbance.
For safety, this target set can be the set of all unsafe states, the backward reachable tube then representing all potentially unsafe, to-be-avoided states~\cite{borquez2024safety}.
While this approach is easily generalisable to many applications, scalability concerns can be a limiting factor~\cite{leeman2023predictive}.

Predictive safety filters 
enforce safety constraints by solving a constrained optimization problem that minimally corrects the nominal control input.
At each time step, the filter predicts the future 
system evolution over a finite horizon and ensures
that all reachable states remain within the safety set.
A key concept is the use of backup trajectories, feasible fallback control sequences that guarantee the system can return to a terminal safe set even if the nominal policy becomes unsafe. 
By verifying the existence of such a backup trajectory
before applying the proposed control,
predictive safety filters ensure recursive feasibility and forward
invariance of the safety set~\cite{milios2024stability}.

% comparison: https://proceedings.mlr.press/v211/leeman23a/leeman23a.pdf


%CBFs rely on
%Lyapunov theory to determine inputs to a system that
%ensure set invariance.

%---
%
%
%Hsu et al.~\cite{hsu2025statistical} introduce conformal robustness,  
%robustifying finite-horizon stability
%and safety guarantees in data-driven nonlinear dynamical
%systems.
%Through a conformally robust control Lyapunov
%function (CR-CLF) and control barrier function (CR-CBF), 
%systematic closed-loop control designs with provable 
%finite-horizon stability and safety guarantees are enabled.


%\subsubsection{Reachability-based approaches}

%based on a set-based propagation
%of all possible system trajectories determined by the
%system inputs and disturbances.

%\subsubsection{Predictive control approaches}




\section{Data-Driven Modeling}\label{modeling}

To enable indirect data-driven control techniques, a model of the to be controlled system needs to be
identified. Techniques in this section are also crucial for direct methods, however, as
the decomposition of the global control problem into the control of sub-systems
is crucial element in all non-centralised large-scale system controller syntheses
where this decentralisation can be configured and is not forced by physical reality.

\subsection{System Identification}

As large-scale systems tend to produce system models that are
unweildly to handle, data-driven model order reduction techniques
receive special attention~\cite{baumann2022data}. Data-driven model order reduction methods rely
only on measured trajectories, frequency response data, 
or impulse responses and produce a reduced representation of the system's dynamics.


\subsubsection{Interpolatory approaches}

A widely-used approach is data-driven interpolatory model reduction.
One such method, the Loewner framework, constructs a reduced linear
model from transfer-function data or sampled impulse responses~\cite{gosea2021datadrivenmodelingcontrollargescale}.
The main element of the Loewner framework is the Loewner Matrix. For two lists of complex number pairs \(u_i, v_i\) and \(\mu_j, \lambda_j\), it is defined as follows~\cite{lowenerIntro}: 

$$\begin{pmatrix}
\frac{v_1-w_1}{\mu_1-\lambda_1} & \dots & \frac{v_1-w_k}{\mu_1 - \lambda_k}\\
\dots & \dots & \dots \\
\frac{v_q-w_1}{\mu_q-\lambda_1} & \dots & \frac{v_q-w_k}{\mu_q - \lambda_k}
\end{pmatrix}$$


The rank of this Loewner matrix then contains information about the minimal admissible complexity of the solutions of the interpolation.
The shifted Loewner matrix \(L_\sigma\) has the entries \(L_{\sigma_{ij}} = \frac{\mu_jv_j- \lambda_iw_i}{\mu_j-\lambda_i}\).
The key insight is that for a linear system, 
these matrices are directly related to the system's internal  % double check this - chatgpt
state-space matrices without needing to know them explicitly~\cite{karachalios2023data}.
The singular values of the Loewner matrix are used to determine the numerical 
rank of the system, which suggests the appropriate order of the reduced model.  
A sharp drop-off in the singular values indicates a good candidate for the 
reduced model's dimension. 
By selecting a small number of the largest singular values, 
one can capture the most important dynamics of the original system.
The reduced-order model's state-space matrices
are then directly computed from the projected Loewner matrices 
and the data vectors~\cite{lowenerIntro}. % double chekck


Another interpolatory model order reduction technique is the AAA algorithm~\cite{nakatsukasa2018aaa}, which builds rational
approximants adaptively by selecting 
interpolation points based on approximation error. 
This method is attractive when only frequency response data is available, 
as it balances accuracy and model complexity with minimal user intervention.
% How does it work??

\subsubsection{Balanced truncation methods}

Balanced truncation~\cite{balancedtruncationOriginal} is a widely successfully employed model order reduction technique for large systems~\cite{salehi2021mixed}, traditionally relying on controllability and observability Gramians and hence access to system matrices.
A data-driven reformulation is presented in \cite{gosea2021datadrivenbalancinglineardynamical}.
The fundamental insight driving this development is that BT does not use the Gramians directly,
but rather their product, which can be approximated from data. The results of the numerical BT method 
can get arbitrary close to those of classical BT, depending on how much computational resources are allocated to the numerical quadrature.



% some more, see below
%\subsubsection{Optimality-based approaches}

%For discrete-time systems, \cite{sakamoto2024data} proposes 
%a data-driven \(h^2\) model reduction technique leveraging the
%discrete-time Lyapunov and Sylvester equations, deriving 
%the data-driven gradient.

\subsubsection{Modal decomposition methods}

Proper orthogonal decomposition is one of the most widely used dimensionality-reduction techniques in dynamical systems.
The key idea is to approximate system trajectories by 
projecting them onto a low-dimensional basis obtained directly from data.
For a dataset \(X = [x_1x_2...x_m], x_i \in \mathbb{R}^n\), proper orthogonal decomposition seeks an orthonormal basis
\(U_r\in\mathbb{R}^{n\times r}\) that minimises the projection error 

\begin{equation}
\min_{U_r^TU_r = I_r} ||X-U_rU_r^TX||^2_F
\end{equation}

This optimization problem is solved by computing the singular value decomposition of the snapshot matrix \(X\). 
The dominant singular vectors define the reduced basis, and the singular values quantify the energy captured by each mode~\cite{eskew2023new}.


A closely related algorithm is Dynamic Mode Decomposition (DMD).
Given snapshot pairs \(S^- = [x_1, ... , x_{m-1}]\) and \(S^+ = [x_2, ..., x_{m}]\), DMD approximates the system by finding
a matrix \(A\) such that 

\begin{equation}
x_{k+1} \approx Ax_k
\end{equation}

The goal is to determine a low-rank subspace of \(A\) and through it represent system dynamics.
One first performs SVD on \(S^- = U\Sigma V^T\), truncating \(U\) and \(V\) to the first \(r\) columns and selecting the first \(r\) singular values from \(\Sigma\).
What value to use for \(r\) depends on accuracy requirements, though a typical choice is to have it retain
a specific fraction of information, such that

\begin{equation}
r = \argmin_j \frac{\sum_{i=1}^{j}\sigma_i}{\sum_{i=1}^n\sigma_i} < \tau
\end{equation}

One can then reconstruct \(A_r = U_rS^+V_r\Sigma_r^{-1}\).
Using the cheap eigen-decomposition \(A_rW = \Lambda W\), one can compute the DMD modes \(\Psi = U_rW\), which 
contain the essential information about the system's evolution and can be used to approximately predict the system's state at any point in time~\cite{HUHN2023111852}.



\subsection{Topology Identification and Decomposition}

An aspect of system identification central for large-scale systems is
topology identification. Whereas classical SI seeks simply to determine 
compact dynamic representations, topology identification 
aims to discover structural information about the subcomponents of the system. 
In large-scale systems, the goal of modeling is often to 
identify a sparse structure therein. This lays the necessary basis for popular 
decentralised and distributed control techniques~\cite{ocampo2011partitioning}.
Formally, given a 
set of variables \(V\), a directed graph \(\mathcal{G} = (V,\mathcal{E})\) 
is to be determined from data, such that \((v,w)\in\mathcal{E}\) if \(v\) has a direct causal effect on \(w\)~\cite{DDC_Overview}.

The system is hence not considered as a single, coherent object
anymore, but rather as a collection of 
different interacting subsystems. 
The two primary decomposition methodologies are physical and numerical. 
In the former, the subsystems are defined by the physical components of the system, such as individual robots in a swarm~\cite{bakule2012decentralized}.
The latter imposes the structure based on computational reasons,
an approach more suited for large-scale systems, as obtaining partitions by physical reasoning can become intractible~\cite{ocampo2011partitioning}.

A widely adopted approach is the Sparse Identification of Nonlinear Dynamics (SINDy) framework~\cite{sindy}.
It constructs a library of candidate nonlinear functions \(\Theta(X)\) 
and identifies governing interactions via sparse regression based on the time-series data \(X = [x_1, ...,x_n]\): 

\begin{equation}
\dot{X} = \Theta(X)\Xi
\end{equation}

\begin{equation}
\Xi = \argmin_{\Xi} \frac{1}{2}||\dot{X} - \Theta(X)\Xi||_2^2 + \lambda ||\Xi||_1
\end{equation}

The resulting sparsity pattern in \(\Xi\) directly defines the 
data-driven interconnection topology. 
SINDyG~\cite{basiri2024sindyg}, an extension of the base SINDy method, 
incorporates the network structure into sparse regression, 
directly identifying model parameters explaining 
underlying network dynamics, allowing the 
capturing of small changes in the emergent behaviour.

Another family of approaches uses causal discovery from
time-series, generalizing Granger causality~\cite{grangerCausalkty} to nonlinear and
high-dimensional dynamics.
Methods such as PCMCI~\cite{pcmci} recover directed
interaction graphs by statistically testing predictive dependencies
in data, requiring no explicit model assumptions.
%Recent variants integrate sparse regression or kernel embeddings
%for improved robustness under noise and temporal correlation.

Once the interaction topology is estimated,
data-driven decomposition partitions the overall 
network into weakly coupled modules. 
This step is essential for scalability, 
as it limits the dimensionality of each identification and 
control problem. Practical strategies include clustering based on 
finding highly connected subgraphs
with balanced number of internal and external connections~\cite{OCAMPOMARTINEZ2011775}
and spectral clustering on dynamic interaction graphs~\cite{TANG20187}.

%Despite being dissimilar in details, most graph decomposition
%algorithms, such as spectral algorithm [94], ϵ-decomposition
%algorithm [93] and Bordered Block Diagonal(BBD) decomposition algorithm [93], try to reduce the total absolute values
%of the weights of the edges that connect various subgraphs to
% minimum.
%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106217

% They can be classified
%according to the properties of subsystem-interconnection structures as
%– Disjoint subsystems
%– Overlapping subsystems
%– Symmetric composite systems
%– Multi-time scale systems
%– Hierarchically structured systems



%The decomposition
%algorithms are based on graph-theoretic representations such as
%epsilon decompositions, Bordered Block Diagonal (BBD) ordering,
%and input/output constrained decompositions.

%Graphical models, sparse identification, factorized dynamics, Koopman ensembles per locality.
%Mean-field reductions for dense homogeneous populations.

%\subsection{Surrogate \& Probabilistic Models at Scale}

%Sparse GPs, ensembles, bootstrap uncertainty, neural net surrogates with uncertainty quantification.
%How to scale UQ: sparse approximations, local GPs, Bayesian neural nets caveats.



\subsection{Koopman lifting for Nonlinear Subsystems}

Most system and topology identification methods operate within
the original state space, limiting expressiveness when dynamics
are strongly nonlinear. Koopman lifting overcomes this by embedding
the nonlinear system into a higher-dimensional, approximately linear space,
allowing the reuse of linear data-driven tools within nonlinear regimes.

Formally, the Koopman operator \(\mathcal{K}_f: \mathcal{F} \to \mathcal{F}\) associated with the state transition map \(f: X\to X\) 
and the Banach space \(\mathcal{F}\) of observables \(g: X \to \mathbf{C}\) is defined through the composition 
\(\mathcal{K}_f g = g \circ f, \forall g \in \mathcal{F}\).
The two core properties making the Koopman operator an exceedingly useful tool are its globality and linearity~\cite{mauroy2020koopman}.
The Koopman operator provides an exact linear approximation 
to nonlinear systems that is globally valid, instead of only around a point or trajectory. 
The main drawback, however, is that it can be infinite-dimensional~\cite{shi2024koopman}.

%Recent research has focused on developing a Koopman MPC technique where one learns a linear 
%predictor (via Extended Dynamic Mode Decomposition or neural nets) and then solves a convex MPC on the lifted space~\cite{LI2025100219}.


A Koopman-invariant subspace is the span of a set of \(m\) basis observable functions \(y_i\)
if all functions \(g\) lying in this subspace, i.e. \(g = \sum_{k=1}^m \alpha_ky_k\)
remain inside this subspace upon application of the Koopman operator, there being a linear combination of the basis functions representing \(\mathcal{K}g\),
\(\mathcal{K}g = \beta_1y_1 + \beta_2 y_2 +  ... + \beta_m y_m\)~\cite{brunton2016koopman}.
On this subspace, a finite-dimensional linear operator \(K\) can be obtained, restricting the Koopman operator \(\mathcal{K}\)~\cite{shi2024koopman}.
When applying the Koopman operator to control scenarios, a Koopman-invariant subspace containing the original state variables \(x_i\) is desired.
This can be an impossible task for some systems, for example a system with multiple
fixed points, as all finite-dimensional linear systems have a single fixed point~\cite{brunton2016koopman}. 

The data-driven determination of the Koopman operator's spectral properties usually involves approximating the operator with finite dimensions~\cite{meanti2023estimating}.
DMD~\cite{dmdseminal} is a popular technique, in large part due to its ease of implementation~\cite{dmdImpl}, extensibility and interpretability~\cite{tu2013dynamic}.
The procedure begins by collecting a time-series of state 
snapshots and organizing them into two matrices, 
\(X\) and \(Y\), representing paired snapshots of the 
system's "past" and "future" states, 
respectively. 
The core objective is to determine the best-fit linear 
operator \(A\) such that \(Y \approx A X\). 
To ensure robustness and manage high-dimensional data, the method 
utilizes the SVD of the state
matrix \(X \approx U_r \Sigma_r V_r^*\) to project the 
dynamics onto a rank-\(r\) subspace~\cite{kutz2016dynamic}. 
The low-rank approximation of the Koopman operator is then calculated as
\(\tilde{A} = U_r^* YV_r\Sigma_r^{-1}\)~\cite{schmid2010dynamic}.



Another wide-spread~\cite{Rowley2009SpectralAO} method for linear functions is tICA~\cite{tICA}.
The methods of eDMD~\cite{Williams2014ADA}, VAC~\cite{vacsem}, KernelDMD~\cite{kerneldmd} and kernel tICA~\cite{schwantes2015modeling} extend the function dictionary to non-linear functions~\cite{meanti2023estimating}.
The latter two kernel techniques resert to being infinite-dimensional, trading off computational efficiency for theoretical guarantees~\cite{koopmanThepry},
though approximate kernel methods are a topic of active research~\cite{baddoo2022kernel, meanti2023estimating, liang2025fourier}.



\section{Model-Free Control}\label{modelfree}

Instead of data-driven modeling, where data approximates the
underlying system to enable model-based control, an orthogonal strand of research
eliminates explicit modeling altogether. 
Such model-free direct data-driven control paradigms, chiefly among them 
Data-enabled Predictive Control (DeePC) and 
Reinforcement Learning, 
have received much attention lately.

\subsection{Data-enabled Predictive Control}

Data-enabled Predictive Control~\cite{coulson2019data} is 
a model-free control framework that extends 
the principles of Model Predictive Control (MPC) 
to a purely data-driven setting.
It eliminates the need for explicit 
system identification by leveraging Willems' Fundamental
Lemma~\cite{willems2005note} from behavioral systems theory, 
which states that all trajectories of a
controllable linear system can be represented
as linear combinations of a single persistently
exciting trajectory.

Given a persistently exciting input-output dataset, DeePC constructs Hankel matrices of past inputs and outputs, then formulates
an optimization problem that directly predicts 
future trajectories and computes optimal control actions 
without identifying a model. As described in \cite{coulson2019data}, the DeePC works as follows:
Taking as input a reference trajectory \(r\), past input-output data \((u_{ini}, y_{ini})\), constraint sets \(U,Y\) and performance matrices \(Q\) amd \(R\),
the first step is to solve for \(g^*\):

\begin{equation}
\min_{g,u,y} \sum_{k=0}^{N-1}||y_k-r_{t+k}||_Q^2 + ||u_k||_R^2
\end{equation}

subject to

\begin{equation}
\begin{bmatrix}
U_p\\
Y_p \\
U_f \\
Y_f
\end{bmatrix}
g
= 
\begin{bmatrix}
u_{ini}\\ y_{ini}\\ u \\y
\end{bmatrix}, \forall k \in [N-1]: u_k\in U, y_k\in Y
\end{equation}

The optimal control sequence is subsequently calculated via \(u^* = U_fg^*\).

Since its introduction, a variety of extensions have 
been proposed to enhance the robustness, 
scalability, and practicality of DeePC.
To improve noise tolerance and generalization 
to unseen conditions, regularized DeePC formulations
introduce penalties on the trajectory coefficients
and slack variables, effectively mitigating overfitting
to specific datasets~\cite{ramadan2025floodgates}.
Scalability can be improved greatly by adding a dimension reduction step to the traditional DeePC 
technique~\cite{wang2024mechanical}.


Its applicabiltiy to large-scale systems is primarily driven through 
distributed and hierarchical DeePC
algorithm formulations, decomposing the 
global DeePC optimization into coupled
subproblems solved locally with limited coordination,
improving scalability and communication efficiency~\cite{YU2024110360,10667672}.

Kernelized DeePC (RoKDeePC)~\cite{huang2023robust} enables the efficient control of nonlinear systems.
It uses a nonparametric predictor of future outputs over a horizon by embedding data into a reproducing-kernel Hilbert space,
seeking a function \(f\in \mathcal{H}\) minimizing a regularized least-squares objective of the form

\begin{equation}
f^* = \argmin_{f\in\mathcal{H}}\sum_{j=1}^N ||y_j-f(z_j)||^2 + \gamma||f||_\mathcal{H}^2
\end{equation}

where \(z_j\) is a suitably defined past-input/output regressor, \(\gamma\) a regularization parameter
and \(|| ||_\mathcal{H}\) the reproducing-kernel Hilbert space norm. 
By the representer theorem~\cite{scholkopf2001generalized}, \(f^*\) can be written as 
\(f^*(\cdot) = \sum_{j=1}^N \alpha_jk(z_k, \cdot)\) for some coefficients \(\alpha_j\), where \(k\) is the chosen kernel.

Given this predictor, control is then formulated as a robust min-max optimization over disturbance sets on inputs and outputs.
To efficiently solve this problem generally non-convex in \(u\), customized gradient descent methods tailored to the RoKDeePC structure are proposed.
These utilise the separable structure of the decision variables by performing projected gradient steps on the input \(u\)
while solving the predictor variable exactly via its convex subproblem. If output constraints are inactive,
a closed-form solution using only linear mappings can be determined,
greatly enhancing computational efficiency~\cite{huang2023robust}.


Another recent work also using kernel functions considers an operator-based DeePC formulation, KerODeePC~\cite{de2025kernelized}.
Jong et al. propose using a product reproducing-kernel Hilbert space
representation of the nonlinear operator that maps
input and initial state to the output trajectory. The goal is to learn the
operator \(G\), such that \(y=G(u)(x)\), where \(G(u)(x) =\Theta^*k_\otimes(u,x)\),
\(k_\otimes\) being the product kernel function and \(\Theta^*\) being the value to optimise over.
Based on this, a DeePC-style optimisation problem formulation can be stated, yielding 
a computationally efficient approach to the control of non-linear systems.

Recent works further address online computational efficiency through recursive
and low-rank DeePC updates, allowing adaptive, 
real-time control under streaming data constraints~\cite{shi2024efficient}.
The DeePC formulation is transformed into a low-dimensional 
form via SVD. Then a fast SVD update mechanism is provided
to avoid recomputing everything from scratch every time new data arrives.
This drastically improves online use viability.


DeePC-style control can be made robust, as proposed in \cite{huang2023robust}, 
a computationally tractable reformulation of DeePC's traditional min-max optimisation
problem via uncertainty sets, providing performance guarantees for the open-loop realized input/output cost.
For partially known systems, hybrid data-enabled predictive control~\cite{watson2025hybrid}
presents an approach providing improved computational cost and robustness
via an inclusion of model knowledge into DeePC. 

To guarantee safety constraint satisfaction, 
recent work proposes hybrid controller architectures
that combine a data-driven predictive element
with a reactive safeguarding feedback loop.
Bold et al.~\cite{bold2025two} design a two-component controller where
the first component is a predictive DeePC controller, whereas the second component is a model-free high-gain funnel or adaptive feedback controller, which activates when the predictive controller cannot guarantee satisfaction of output or trajectory constraints.
This architecture ensures constraint satisfaction
under worst-case conditions: by switching or
blending to the high-gain feedback when needed,
the system never drifts into unsafe regions,
even while the data-driven component learns or adapts.
Another approach for proving safety is using reachability analysis, 
decoupling the system into error system and nominal system,
the former prividing data-driven reachability sets 
for the enhanced safety constraints
in the nominal system~\cite{li2024robust}.
This is directly relevant for large-scale system control, as these approaches 
can be used in the safe control of subsystems in situations where the global safety
constraint is decomposable into local conditions for each subsystem.

\subsection{Reinforcement Learning}

Reinforcement Learning (RL) has recently become a popular 
method for dealing with the ever-growing complexity of modern systems, 
providing the benefit of determining optimal control policies without 
necessitating detailed system models~\cite{9261330}.
RL-based controllers require no labeled datasets and are instead guided by feedback and learn in a trial-and-error fashion,
making them well-suited for large-scale systems where 
explicit system models are missing for reasons such as 
nonlinear dynamics and multi-timescale operations~\cite{rfAndIntro}.

Another advantage of RL is its statement of the control problem as Markov decision processes
(MDPs), providing great generality. 
They are applicable to nonlinear
and stochastic dynamics, nonquadratic reward functions and even
continous states and actions through numerical
function approximation techniques~\cite{BUSONIU20188}.
Weaknesses include high data requirements and long convergence times~\cite{BARBALHO2022108315},
hyperparameter sensitivity~\cite{smartGridRL}, potentially high computational costs [cite], and  
often missing formal stability guarantees~\cite{BARBALHO2022108315}.



%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11162524 this is good

%In the context of microgrids, an RL agent might take the following form~\cite{mfrlMG}:

The goal is to find a policy \(\pi: S \to \mathcal{A}\) mapping 
states to actions maximising the expected cumulative reward

\begin{equation}
J(\pi) = \mathbb{E}_\pi \left[\sum_{t=0}^\infty\gamma^tr(s_t,a_t)\right]
\label{eq:reinforcement}
\end{equation}

\noindent \(\gamma\in [0,1]\) denotes a factor balancing immediate against
long-term goals and \(r\) encodes control objectives as scalar rewards, possibly differing across individual controllers, e.g. in hierarchical systems~\cite{mfrlMG}.

To enable real-time online reinforcement for large-scale systems,
approximation approaches have been proposed, where the input-output history is
transformed into a shorter set of data, being the basis for a lower-dimensional
inferred controller than the original, decreasing the time complexity from \(O(L^6)\) to \(O(L^4)\), where \(L\) denotes a natural number valued design parameter of the algorithm~\cite{sadamoto2021fast}.


A central distinction is to be made between online and offline RL.
Traditionally, RL is viewed as an active
learning process requiring interaction with the environment. 
This can, however, be expensive and dangerous,
and must rely on a smaller set of data than could be gathered for offline datasets, 
due to them only having to be collected once, instead of during each run~\cite{conservativeQLearning}.
Offline RL methods, the learning from entirely pre-collected, offline data, without on-policy interaction, 
have been developed accordingly. Challenges to be solved with this approach include the inability of exploration, 
the counterfactuality of queries and distributional shift~\cite{Levine2020OfflineRL}.
The learned policy may select actions that are poorly represented
in the dataset, leading to extrapolation errors in value estimates.
To mitigate this, a range of regularisation strategies have been proposed.

One range of techniques centers around the 
idea of Conservative Q-Learning (CQL)~\cite{conservativeQLearning}.
CQL solves issues off-policy RL algorithms face by learning a conservative estimate of the value function,
avoiding over-estimation and yielding much better
performance. A tighter lower bound is achieved by 
Mildly Conservative Q-learning
(MCQ)~\cite{mildlyconservativee}, actively training out-of-distribution actions by constructing them proper
pseudo target values. 

Offline RL has also been extended to multi-agent and distributed settings. Counterfactual Conservative Q-Learning (CFCQL) proposes a method  
counterfactually determining conservative regularization
for each agent separately and subsequently combining them linearly, leading to an overall conservative estimation~\cite{NEURIPS2023_f3f2ff95}.

To achieve robustness in reinforcement learning, the maximisation problem presented in \cref{eq:reinforcement}.
can be reformulated, depending on where the uncertainty is assumed to stem from~\cite{moos2022robust}. In the case of an unknown transition matrix \(P\), fixed and lying within a known uncertainty set \(\mathcal{U}_P\), this might look as follows:

\begin{equation}
\max_{\pi\in\Pi}\min_{P\in \mathcal{U}_P}\mathbb{E}_{P,\pi} \left[\gamma^t r(s_t,a_t)\right]
\end{equation}


Since reinforcement learning approaches make random decisions in the process of exploration
that can violate safety constraints and lead to unacceptable system behaviour, naive RL methods
cannot be applied to many safety critical areas~\cite{yu2024safe}.
One approach to safe RL is to utilise Lyapunov functions determined through linear programming to
guarantee safety and robust learning~\cite{chow2018lyapunov}.
An alternative methodology involves adding control barrier functions, dropping the reward to minus infinity in
safety violation situations, ensuring the learned optimal control policy respects the safety bounds~\cite{vu2021barrier}.
These CBFs can further be learned efficiently using neural networks, as demonstrated by \cite{yang2023model},
improving this method's applicabiltiy to large-scale systems.
A formal methods based approach presented in \cite{hasanbeig2020cautious} safety constraints 
expressed in LTL guide the exploration. A key drawback of this, despite success in the safety dimension, is the necessity of manual 
formulation of these constraints~\cite{gu2024review}. 


\section{Control Architectures for Large-Scale Systems}\label{architecture}

% https://pdf.sciencedirectassets.com/777797/1-s2.0-S2666792424X00025/1-s2.0-S2666792424000155/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGkaCXVzLWVhc3QtMSJGMEQCIAegW7oXZKt3V9iBiEi2msqM%2BAY9A%2BPnHt18CO8%2BJYaCAiBoGcwAz5MjgiQ%2B4cRBI8XgsRtqQCxLZFfd4fvDJoqWRSqyBQgxEAUaDDA1OTAwMzU0Njg2NSIMMYuZTXbWxxUOh%2FfyKo8Fye1UeN2ILOpLtc%2FIb2pNV5TpvXUMeJG9ty9tlHXnkecB3WvX2h9g%2FH0P8NpDY6ufHHbh5cpFPlre%2FdfskqzV6o%2FblkED1IVm2WmMlZcSjkMZmht0AoQvX2oRH%2BuLGlSYpZlJAYUps1c%2BsgAnXlyXTOIYjBuzacVG6NB7rpVKsvgdzW2gnkxqjLz%2BnsS3CgAUPivEIVnN%2BG%2BAaQjLhSpKw%2Ba80Lp6alALVrJVc%2FVhfYZm4%2FJsgBuscEXsc5CJjLUUlY4Nus%2FFuSf7BIdTHTsI89VhQr5zPnKIpctRYlrxYMq8dHCKQMXJvZReLhUGUgLDhZMRqxm%2Fnn8OlN9ST%2FfSuN%2BKp4yVQI19TjGDLYHVegb032PEwh3twWlj8IVxNypcBq0r%2BW0Z2eeO%2F3PsfL1LOZJIEZrh2k9WGr%2Bv%2BERbOexA6KLvTGp2v4PVhFjD9m3GTaZmKuCUNI7qhbrGHAr26g2wFuWWGNahHxekZKxz6UijxHnMRuM5%2BnBkLB40NT2ewjbT4RdIjXJC4k4Y2uOFe9Xg8ySbHDpq1%2FbtwiiKqD75807SeBlKjkNbYmXj1decWIJuzDzEh1SqkPr6qb%2B4DbKtbok2txp5aSSBmTNjA%2FB8CsPGFh3LKIM5q5nVAFHTifdCcAPF0mR%2BeIjya0UL%2BRiW84hqopNC0upT2vN0gXHJ%2B9lV5Hw2n3HNnyughWW0A8cZVKyrxM%2BLh1giUBGUJ4gVfJeK7gTnT4HRSTETrW0%2BOT%2Bbv4yTc1CHrd9kacMp1S%2FlxJOcaT%2F5nUHbeX8qXOscXPlW5LN7hAuNS4MStaa1sSxcTQ29UEVL%2FQZ2%2BM%2BRziaJAzeR2V5DzJOAchRh5rc5w3VEgQu78PntDJ%2BQjjCA4PnJBjqyAaYDkrd09y6EdJPfV%2B1ANuT%2FlIKHvBfvvEXvUML6COsvmNPtlpliOUUuULrXC41pdkrcnPWKqgKyyDa%2B8zmlg2xdDJUMpW1Myf96IMiFjwiEs29tIjR29L5qvd83Tw8l9ogGK0I4MCtuK06bTav5TccoqYdDuVm1ckAT20DqiGIDWSRPqoQjHitHLnfVSAkk4%2FgPka0WFemDutl%2B3Y4P1BIwjw%2Byx81lKKhLoWRKQRDt%2BGY%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251214T091122Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYT2S7FDUI%2F20251214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=5d489fcf529487e486b06c5ecba3a76628a5ea534a8b7bf1bee25a8726ad7f33&hash=bed937f3c0baeabfb6c35e812db2d332048e195209781c435cf7e2ec4583b357&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2666792424000155&tid=spdf-884412dc-733d-4aba-a099-204207f7dde7&sid=74e7365b827934490d489a73f00ba09a78eegxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1b125f05060059540700&rr=9adc92ceadbb8f2b&cc=at


The scalability of data-driven control 
depends not only on the learning or 
identification methods employed, but also on the 
architecture through which control decisions are coordinated.
The control architecture determines how information
is shared and decisions are made within a large-scale
system.
Large-scale systems pose fundamental challenges for classical control architectures.
As system dimensions and interconnections grow, centralized strategies become computationally intractable and communication-limited~\cite{ma2024efficient}.

To address these challenges, the three principal paradigms of decentralized, distributed, and hierarchical control have evolved, each with characteristic trade-offs in scalability, performance, and robustness. 
Beyond this tripartite classification, 
modern work increasingly integrates hybrid architectures, 
blurring traditional boundaries.


\subsection{Decentralized control}

In decentralized control, each subsystem maintains 
an independent controller relying solely on local 
measurements and actuation. 
No online communication occurs among controllers, 
and couplings are treated as exogenous disturbances or 
modeled implicitly~\cite{wang1973stabilization}.
This structure yields high robustness to communication 
failures, straightforward scalability
and is attractive for large-scale systems where global data aggregation is infeasible or 
undesirable due to privacy, latency, or safety concerns, 
yet typically sacrifices global optimality, as individual controllers do not have as much information regarding the state or output of the system as a centralized one would~\cite{ge2017distributed}.
In some definitions of decentralised control information exchange is allowed before and after the decision making process, 
simply restricting the controllers from actively negotiating~\cite{bemporad2010decentralized}. 

% https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127863&casa_token=Ko36uD2854kAAAAA:ynMRD7IwURNZU4uS1boXJgMnyyIX5uHKjdMOfL0Iw4WQ6snn9hCol0oUsfaFqD-1IQBFxbjnBWaB9A
% https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10053641&casa_token=omf8nd2_9yAAAAAA:A8q6bRC4elyGWE9BYTfH8e01ilCE7Hmjpn_huSnY8rP8ZyhpDaHSAx2UrLYWgXHLCidFqDq9gIRuFw
% https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10127863&casa_token=Ko36uD2854kAAAAA:ynMRD7IwURNZU4uS1boXJgMnyyIX5uHKjdMOfL0Iw4WQ6snn9hCol0oUsfaFqD-1IQBFxbjnBWaB9A


A natural approach to decentralised control is the extension of the popular MPC to this setting. 
In general, data-driven MPC can be formulated as presented in \cite{berberich2024overview} for noise-free data:
Given input-output data \(\{u_k^d, y_k^d\}_{k=0}^{N-1}\) and the goal 
of tracking a setpoint \((u^s, y^s)\) under the constraints \(u_k\in \mathbf{U}, y_k\in \mathbf{Y} \forall k\in \mathbf{I}_{\geq 0}\),
following optimal control problem must be solved:

\begin{equation}
\min_{\alpha(t), \bar{u}(t), \bar{y}(t)}\sum_{k=0}^{L-1}||\bar{u}_k(t)-u^s||_R^2+||\bar{y}_k(t)-y^s||_Q^2
\end{equation}

such that 

\begin{equation}
\begin{bmatrix}
\bar{u}(t) \\
\bar{y}(t) 
\end{bmatrix}	
= 
\begin{bmatrix}
H_{L+n}(u^d) \\
H_{L+n}(y^d)
\end{bmatrix}	
\alpha(t)
\end{equation}

\begin{equation}
\begin{bmatrix}
\bar{u}_{[-n,-1]}(t) \\
\bar{y}_{[-n,-1]}(t) 
\end{bmatrix}	
= 
\begin{bmatrix}
u_{[t-n,t-1]} \\
y_{[t-n,t-1]}
\end{bmatrix}
\end{equation}

\begin{equation}
\bar{u}_k(t)\in \mathbf{U}, \bar{y}_k(t)\in \mathbf{Y},k\in \mathbf{I}_{[0,L-1]}
\end{equation}

Running the algorithm requires first choosing an upper bound on system order \(n\), prediction horizon \(L\), positive definite
cost matrices \(Q\) and \(R\), constraint sets \(\mathbf{U}\) and \(\mathbf{Y}\), and setpoint \((u^s, y^s)\). Then 
for each timestep, the optimisation problem can be solved and the first optimal input component applied to the system, repeating until convergence~\cite{berberich2024overview}.

To illustrate the changes in a decentralised MPC method,
the linear dynamics of the the \(i\)th subsystem controller in a model-based view could be described as~\cite{kofler2022agent}

\begin{equation}
\dot{x}_i = Ax_i + B u_i +Ex_c
\end{equation}

where \(E\) denotes the disturbance based on the central state \(x_c\), one of its sources being the actuation from other subcontrollers.

Chen et al.~\cite{chen2020decentralized} propose a decentralised MPC system for nonlinear processes
where neural network models are trained for each subsystem and used as prediction models. 
This approach resulted in improved computational cost compared to the centralised approach, while ensuring ensure
closed-loop state boundedness and convergence.
Decentralised MPC can even work in application domains that tend to favor 
a different kind of architecture, such as microgrids \cite{karami2019decentralized}.

The more popular approach to predictive control in decentralised architectures is the DeePC one, though.
dDeeP-LCC~\cite{shang2024decentralized}, a decentralised formulation of DeePC, achieves better safety guarantees and smaller computational cost than a centralised formulation, while being naturally privacy preserving.






%Recent research focuses on enhancing local 
%data-driven controllers with structural 
%priors and regularization that implicitly 
%encode coupling information. 
%Markovsky et al. [1] demonstrated that 
%behavioral system identification can yield locally 
%data-driven DeePC controllers with guaranteed 
%feasibility and stability in power networks, without 
%requiring explicit coupling models. 
%Di Lorenzo et al. [2] introduced continuification 
%control, a density-based approach where each agent 
%reconstructs a local estimate of the global state 
%density from sparse samples, achieving emergent global 
%coordination from fully local data. In large-scale 
%energy systems, 
%Yu et al. [3] combined local identification and 
%reinforcement-based optimization to enable a
%daptive voltage and frequency control in 
%distributed grids.



%Despite its scalability and resilience, 
%purely decentralized data-driven control 
%remains challenged by incomplete information 
%and model drift. Current research therefore 
%emphasizes local adaptation - re-identifying models or
%updating policies online to preserve performance as 
%operating regimes shift. 
%Robustness to unobserved couplings and noise remains 
%a core open problem.



%https://pure.tue.nl/ws/portalfiles/portal/167568910/1312561_Anupama.pdf
%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810289&casa_token=0MxFKu6tynsAAAAA:28_1yQLNbASP1_ldp1jf39HW8Ol3EEJ7Ru8A81yKw7theSVp4tLAlQepsyR-KnBVNG77H6e85PvPxw

\subsubsection{Robustness}

Robustness in decentralized data-driven control addresses 
the challenges of uncertainty in subsystem interactions and
disturbances acting on local dynamics. 
Unlike centralized architectures, 
decentralized controllers cannot rely on global state
information, making explicit robustness formulations essential
for guaranteeing stability and constraint satisfaction
under limited information exchange.

A central approach to robust decentralised predictive control 
introduces bounded uncertainty sets for each subsystem.
These sets capture not only local disturbances and measurement noise, 
but also partially observed inter-subsystem coupling and network effects.
This method has been successfully employed in the context of
both predictive control~\cite{s22228709,shang2024decentralized} and
adaptive dynamic programming~\cite{li2023decentralized} in decentralised architectures.

Overall, decentralized robustness mechanisms scale well computationally, 
usually linearly with the number of subsystems, as they avoid global optimization and communication entirely.
However, this scalability tends to not stem from exploiting the large-scale structure of the system,
but is rather a consequence of a naive decomposition of the global robustness goal
to the subsystem level, yielding limited system-level robustness guarantees under strong coupling conditions.



%Distributionally robust formulations achieve this by 
%optimising against ambiguity sets of empirical data,
%yielding probabilistic guarantees on constraint satisfaction~\cite{coulson2019regularized}.
%Alternatively, reachable-set or zonotopic constructions
%can be derived from local data to bound the effect of
%coupling and noise without explicit model identification~\cite{alanwar2022robust}.




%
%These uncertainty sets can be constructed empirically
%from measurement data, statistical confidence intervals,
%or physical limits on system evolution[CITE].
%
%Shang et al.~\cite{shang2024decentralized} proposed
%such a decentralized robust
%data-driven predictive control scheme, where each subsystem
%estimates a time-varying disturbance bound from local observations
%and embeds it into the predictive optimization.
%The resulting controller achieves smooth and safe closed-loop behavior
%even under strong coupling uncertainty.
%Comparable ideas have also been successfully applied in other domains, 
%such as robust decentralized control for microgrids, 
%where local controllers compute data-driven disturbance 
%bounds using voltage and power measurements to maintain
%grid stability under communication and measurement noise~\cite{s22228709}.
%
%
%Robustness can then be incorporated into the local optimization in several ways.
%The most direct is the min-max formulation, 
%where each subsystem solves a saddle-point problem ensuring
%feasibility for all admissible uncertainties within its set. 
%While this approach provides strong guarantees,
%it can become conservative and computationally demanding, requiring
%careful engineering to maintain practical employability~\cite{xie2026data}.
%
%Constraint tightening and tube-based schemes are
%often preferred in practice.
%In these formulations, a nominal data-driven controller
%is augmented by a local feedback law or margin
%that confines the closed-loop trajectory within
%a robust invariant tube around the nominal prediction,
%maintaining safety without excessive conservatism~\cite{coulson2019regularized,shang2024decentralized}



%The application area of microgrid control has brought about much of the research on robust decrentralised control approaches.
%As for model-based methods, \cite{baghaee2017decentralized} proposes a decentralised robust mixed \(H_2/H_\infty\) controller

%\cite{li2023decentralized} proposes a robust adaptive dynamic programming approach to decentralised control taking into account both actuator faults and external disturbances. 



\subsubsection{Safety}


The decentralised control of large-scale systems poses a special challenge
for safety guarantees, as the local subsystem controllers have to ensure constraint satisfaction
despite only implicitly gaining information from the other subcontrollers, 
no direct communication channel being available, safety hence having to be enforced locally and independently.
While this tends to ensure a complexity linear in the number of subsystems, safety guarantees
extending beyond those decomposing into local requirements can only be met under restrictive assumptions. 
A common method~\cite{zhang2023data,hashemnezhad5371728safe} for achieving such guarantees is the 
use of neural networks projecting the proposed action onto the nearest safe one, the networks having been
trained on historical data to estimate the local impact of control actions on system states. 

Ultimately, research on safety for decentralized data-driven control remains limited.
The lack of communication fundamentally restricts the ability to guarantee global
safety properties in strongly coupled systems, making
decentralized safety mechanisms most appropriate
for settings with inherently local constraints.

\subsection{Distributed control}

%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11108244&casa_token=VehPJM9m_hEAAAAA:3Bupc1FUPTPLgj8_M5IRi0bldulWFqXMWGRFIL9m9QTyk5ZJUKmMSrGcIH4sxvDlW5FZOeJIgs-2Ow


As opposed to decentralised control, subsystems in distributed architectures share information among system components.
This enhances the coordination capabilities of the agents, incurring improved scalability and robustness~\cite{ge2017distributed}. 
Factors that need to be considered in this design are communication delays and reliability. 


\subsubsection{Distributed Model Predictive Control (DMPC)}

A familty of techniques having been researched deeply for decades~\cite{SCATTOLINI2009723} is the collection of Distributed Model Predictive Control methods.
In a DMPC setting, each subsystem solves a local MPC and exchanges certain pieces of information, which is considered in addition to dynamics, constraints and objectives.
DMPC systems can be approached from a bottom-up or
a top-down perspective: 
either a collection of autonomous systems is considered, introducing communication
for coordination purposes, or from the
view of a monolithic system being decomposed into
subsystems, coordinated under constraints of
communication and processing power~\cite{maestre2014distributed}.

In non-iterative approaches, agents 
coordinate only once per sampling instant to solve
their optimization problems, providing simple and fast coordination, albeit at the cost of sub-optimal performance~\cite{maestre2015comparison}.
Iterative DMPC strategies aim to 
overcome the sub-optimality of non-Iterative
methods by repeatedly exchanging information until a
consensus or near-optimal solution is reached~\cite{wu2024iterative}. 
To realise this efficiently, decomposition techniques such as the alternating
direction method of multipliers~\cite{rostami2017admm}, the dual fast gradient method~\cite{wu2024iterative}
and Nesterov-accelerated-gradient~\cite{8304602} approaches have been used successfully.

For computational and operational efficiency reasons, constraining the communication of subsystems to a local neighbourhood
can be advantageous. DLMPC~\cite{alonso2022distributed} and the corresponding data-driven formulation \(D^3\)LMPC~\cite{alonso2022data}
use the system level synthesis framework~\cite{anderson2019system} to generate a distributed model-predictive controller, which shares information only locally, the neighbourhood sizes being adjustable.
The system level synthesis framework parameterizes the entire closed-loop system using two transfer matrices called system responses \(\{\Phi_x, \Phi_u\}\), such that 
\(\begin{pmatrix}x\\u\end{pmatrix} = \begin{pmatrix}\Phi_x\\\Phi_u\end{pmatrix}w\), \(w\) being the exogenous disturbance.
The data-driven formulation uses Hankel matrices to replace to closed-form system responses~\cite{xue2021data}.
DLMPC achieves the restriction of neighbourhood size, the maximum number of hops in the communication graph a subsystem can communicate with, 
through a locality constraint on the system response.
The data-driven DLMPC provides the same guarantees as the standard DLMPC, namely recursive feasibility, stability and convergence for both nominal and robust settings~\cite{alonso2023distributed}.

\subsubsection{Multi-Agent RL}

In Multi-Agent RL, each agent controls a subsystem 
and must learn policies in a partially observable environment while interacting with other agents.
As in model-based methods, centralised control via RL can grow intractible.
In a multi-agent network \(\mathcal{G}= (V,\mathcal{E})\)
each agent \(v_i\in V\) chooses an action \(u_i\in U_i\)
and communicates with neighbours along the edges \((i,j)\in \mathcal{E}\), 
receiving a global reward \(r(s,u)\). 
The joint action space \(U = \bigtimes U_i\) then grows too large to
efficiently control in a centralised fashion~\cite{chu2019multi}.

%The central assumption MARL in the context of Q-learning, the most common approach, 
%is the decomposability of the global Q-function, distributing each \(Q_i\) to the corresponding local agent~\cite{chu2019multi}:

%\begin{equation}
%Q(s,u) = \sum_{v_i \in V}Q_i(s,u)
%\end{equation}

A central distinction is to be made between 
centralized training with decentralized execution and decentralized training with
decentralized execution. 
In centralized training with decentralized execution, agents can freely communicate during the learning phase, which is performed by a centralised
algorithm. The policies are, however, executed in a decentralised fashion, agents communicating only via 
restricted channels~\cite{foerster2016learning}.
In decentralized training with decentralized execution, independent learners train policies without explicitly modeling other 
agents, which provides improved scalability~\cite{du2021survey}.


%https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10675394

\subsubsection{Event-triggered distributed control}

A key disadvantage of many distributed control approaches
is the necessity of high-frequency communication between the sub-controllers.
Solving this issue is the aim of event-triggered control, 
constructing trigger functions that 
communicate only when necessary~\cite{9354049}.
This can further be extended to a system where the local controllers
are deactivated, the control action held constant until a preset condition is met,
reducing computational burden~\cite{wang2020event}.

Each local controller continuously
monitors its state and transmits updates only
if a predefined triggering condition,
typically based on state error or
performance degradation, is violated~\cite{hirche2020distributed}.

One notable work by Yang et al.~\cite{yang2019adaptive} combined this with a reinforcement learning apprach
developing a distributed
control scheme tailored to large-scale interconnected nonlinear systems
under uncertain couplings.
Each local subsystem implements an
adaptive-critic architecture to 
approximate its own optimal control
policy directly from collected state-input data.
The authors integrate experience replay, 
buffering past trajectories to accelerate learning
and stabilize convergence, 
and embed event-triggered communication to 
reduce inter-subsystem data exchange 
while still guaranteeing closed-loop stability. 
Crucially, the formulation accommodates
unknown subsystem interconnections by treating them
as disturbances while enforcing local
Lyapunov-based dwell and time-trigger
conditions to preserve global stability despite decentralisation.
The propsed method is a scalable data-driven algorithm
that yields stabilising controllers for each node
in the network with bounded communication and minimal
modelling assumptions.


Event-triggered data-driven distributed control has found application in a variety of areas.
Bu et al.~\cite{bu2025event} develop a data-driven control algorithm
for multimicrogrid interconnected systems with time delays, 
triggering communication only when the control error exceeds a tunable threshold,
proving convergence via Lyapunov theory.
Zhu et al.~\cite{10337762} propose a method for connected heterogeneous vehicle platoon control
considering sensor faults, network resource usage minimised through the effective use of triggering conditions.
Yu et al.~\cite{yu2023distributed} develop an iterative learning approach for the control of 
Multiple High-Speed Trains with sitching topologies, proving 
stability and reduced bandwidth occupancy while retaining
sufficient performance.


\subsubsection{Robustness}

The key advantage distributed architectures have over decentralised ones with regards to robustness is the ability to explicitly
communicate among subsystems. While this allows for distributed robust control optimisation, it introduces the need for
more extensive performance considerations to scale to large-scale systems.  

In \cite{wang2024data}, robustness is achieved by explicitly modeling uncertainty on both subsystem
dynamics and interconnection terms, and embedding these uncertainty descriptions into a distributed
robust optimization problem whose constraints are decomposed according to the network graph.
Rather than enforcing robustness independently at each node, 
tightened coupling constraints are coordinated across the network so that worst-case
uncertainty propagation is bounded at the system level. 
This graph-structured decomposition enables robustness guarantees that
scale with the degree of interconnection rather than the total number of subsystems,
making the approach especially applicable to sparse networks.

A robust distributed model-free controller is constructed in \cite{li2022robust}
for the domain of volt/VAR regulation over power distribution networks. 
Each local agent uses robust regression 
to mitigate bad measurement data
and iteratively updates its control strategy via a distributed alternating
direction method of multipliers algorithm enhanced with Nesterov acceleration, enabling scalability via
complexity growing approximately linearly with the number of direct connections at each subsystem. 
Efficient robustness is hence achieved via the model-free, data-driven feedback loop
which tolerates measurement errors and model mismatch,
the distributed optimization architecture where only limited peer exchange is required and
convergence is accelerated, and decentralized local correction at each node which ensures
the system stays robust to both local disturbance and coupling uncertainties.

Overall, robust distributed control for large-scale systems departs from classical robust
design by treating uncertainty as a network-level phenomenon rather
than simply a collection of independent local disturbances.
The reviewed methods demonstrate that scalability
depends on the exploitation of interconnection structure,
coordinating robustness margins across subsystems.


\subsubsection{Safety}

%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025385&casa_token=qjvIbDAx4-IAAAAA:M_4c8XzQjozwgwnYrNPirBtIXLgr0FI3ZlBIOL4bbFzo0MrfkKRA-L2I-HbvmhhS9Utle5M0ykQ&tag=1


Recent work in distributed hierarchical control
emphasises certifiable safety through layered protocols
that ensure safe interaction among agents under
communication and dynamic coupling.

Khaledi et al.~\cite{khaledi2025data} constrain a direct data-driven distributed controller for multi agent systems
via Control Barrier Functions incorporating quadratic programming optimisations. 
The online computational complexity is dominated by the interior-point quadratic programming problem, which is, for \(m_i\) being the control input
dimension for agent \(i\), \(\mathcal{O}((\sum_im_i)^3)\) due to the factorization of
the Karush-Kuhn-Tucker system for dense data~\cite{ye1989extension}.
As a result, this approach is primarily suited to moderately sized networks,
highlighting a fundamental limitation of CBF-based safety mechanisms
whose safety constraints are enforced through globally coupled online optimization problems 
when applied to large-scale systems.

In contrast, the Trajectory-Tube Distributed Explicit Reference Governor proposed in \cite{convens2022safe} explicitly targets scalability by decoupling safety enforcement across agents through predictive safety tubes that account for higher-order nonlinear dynamics and inter-agent coupling.
Safety information is exchanged only locally among neighboring agents, preventing the
propagation of global constraints and enabling safety certificates whose complexity
remains bounded as the swarm size increases. 
This structural localization of safety guarantees allows the method
to scale to large, resource-constrained UAV swarms while maintaining 
constraint satisfaction under limited communication.

While research on safety in distributed data-driven control architectures remains limited,
the presented 
methods suggest that safety guarantees in large-scale systems are feasible only
through spatial localisation. 
Approaches that prevent the global coupling of safety constraints and bound per-agent computation and communication
hence seem to be more promising for large-scale system scenarios.


%\cite{shaham2024learning} presents a safe distributed certifiably stable neural network controller  for heterogeneous platoon control.


\subsection{Hierarchical control}

% A Data-driven Hierarchical Control Structure for Systems with Uncertainty

In hierarchical control scenarios, the control structure is conceptually arranged in multiple levels.
The higher level controllers coordinate the actions of the lower level ones, 
being responsible for meeting the overall goal of the large-scale system~\cite{SCATTOLINI2009723}.
Hierarchical control could be viewed as a special case of distributed control, 
where some controllers take on special coordination roles.

This paradigm allows coordination of complex large-scale systems 
by assigning high-level layers to strategic, long-horizon decisions
and lower-level layers to fast, local actuation.
The approach mitigates the curse of dimensionality
inherent in centralized optimization and can improve robustness
and scalability compared to purely distributed schemes~\cite{SCATTOLINI2009723}.

\subsubsection{Architectural principles}

A canonical three-layer hierarchy distinguishes between:

\begin{itemize}
\item Supervisory layer (Level 1): Performs system-wide coordination, optimization, and constraint management. It determines global references or resource allocations for subordinate controllers.
\item Coordination layer (Level 2): Translates supervisory commands into feasible sub-objectives for each subsystem, handling coupling constraints and communication among local controllers.
\item Local control layer (Level 3): Executes low-level control laws (e.g., MPC, RL, PID) to track references or regulate states under real-time constraints.
\end{itemize}



This division of control responsibility originates
from industrial process control~\cite{terry1983hierarchical} %double check this
and has since
been generalized for power systems~\cite{vasquez2010hierarchical},
transportation networks~\cite{10667672}, and multi-robot systems~\cite{ju2021hybrid}.
The separation enables each layer to operate at different
sampling rates, leading to computational tractability and
improved modularity~\cite{maestre2014distributed}.

\subsubsection{Data-driven hierarchical model predictive control}

Hierarchical Model Predictive Control extends MPC to a multi-level framework, where upper layers solve relaxed or aggregated optimization problems whose 
outputs guide lower layers~\cite{SCATTOLINI2009723}. 

Shi et al.~\cite{shi2020data} present an indirect data-driven hierarchical control structure for systems operating under uncertainty.
The controller lower in the hierarchy identifies a linear approximation between the higher-level signals and output, whereas the higher-level controller component  
has the task of dealing with the modeling errors and environment uncertainties.

As for direct data-driven methods, model-free
formulations such as hierarchical DeePC have emerged~\cite{10667672}, demonstrating
such a structure for autonomous mobility-on-demand fleets: the upper layer optimizes
global vehicle repositioning and the lower layer applies local DeePC to individual agents.


\subsubsection{Reinforcement Learning}

One of the early papers in the field of hierarchical reinforcement learning was \cite{singh1992transfer},
proposes a technique of decomposing tasks, solving them individually using Q-modules and sharing solutions across multiple composite tasks,
laying the groundwork for the widely successful hierarchical reinforcement learning framework. 

% defintiion for HRL https://arxiv.org/pdf/2011.04752

Formally, given a high-level controller \(Q_1\) declaring the subgoal \(g\) and the lower-level controller \(Q_2\) generating the corresponding action \(a\),
hierarchical reinforcement learning can be expressed as follows~\cite{naveed2021trajectory}, where \(Y\) denotes the Bellman Target:

\begin{equation}
Y_t^{Q^1} = \sum_{t'=t+1}^{t+1+N} R_{t'} + \gamma \max_g(s_{t+1+N},g)
\end{equation}

\begin{equation}
Y_t^{Q^2} = R_{t+1} + \gamma \max_aQ(s_{t+1}, a| g)
\end{equation}


Applying hierarchical reinforcement learning naively to large-scale systems can lead to computational inefficiency and convergence difficulties due to the inherent challenge of a high-dimensional action space,
leading to a trend towards combining hierarchical and distributed reinforcement learning, intending to reduce task complexity and accelerate training speeds.
One such work is \cite{chen2023distributed}, a distributed hierarchical controller using deep reinforcement learning.
The authors develop a new framework coined hierarchical reduction reinforcement learning (HR2L),
addressing the critical challenge of computational inefficiency in deep reinforcement learning for large-scale power grid emergency control.
HR2L is based on a two-layer hierarchical decomposition that achieves efficient and accurate action space reduction via a self-supervised learning algorithm. 
By training a top layer to identify a small effective action space,
it significantly reduces the control complexity for the bottom layer.
Furthermore, an experiences sharing-based distributed architecture is integrated
to enable parallel training and enhance scalability. 
This approach substantially improves upon prior art in convergence speed,
solution quality, training robustness, and adaptability to large-scale systems.

% MFAC is not reinforcement learning :/
%To more efficiently handle non-linearities, \cite{deng2025extended} 
%proposes a hierarchical control scheme for  
%multi-agent systems that combines partial dynamic linearization 
%with an extended state observer (ESO). 
%A distributed estimator 
%that generates per-agent reference trajectories while
%explicitly handling communication delays is constructed for the high-level control.
%At the lower layer, each agent's nonlinear, 
%non-affine dynamics are reformulated into an affine 
%form that separates a linear input gain
%from all unmodeled nonlinearities. 
%Those nonlinear leftovers are treated as an extended state
%and estimated by a linear ESO, while the input gain is
%updated via an adaptive law.
%Bounded tracking error are proved using Lyapunov
%and Halanay-type delay arguments and improved tracking
%and more stable coordination compared to prior approaches are shown via simulations. 




\subsubsection{Robustness}

Hierarchical control further offers a natural option of mixing different approaches to control.
This approach is especially popular for constructing robust reinforcement learning based controllers, as
robustness properties can be inherited from the other controller, while still reaping some of the benefits 
of RL. [citation needed]
In \cite{li2020learning}, such a hybrid hierarchical controller for robotic in-hand manipulation is proposed, where the low-level controllers being 
first-principles based, whereas the higher-level controller uses reinforcement learning, leading to a controller
robust against noise-affected observations of the object pose 
and inaccurate kinematic and dynamic models.
A similar approach is taken by \cite{naveed2021trajectory} for robust trajectory planning of autonomous vehicles, 
the high-level reinforcement controller guiding low-level PID controllers.

Another approach for robustness in hierarchical architectures 
is to combine a distributionally-robust supervisory optimizer 
with certified local controllers: 
the supervisory layer computes plans under data-driven ambiguity sets
(Wasserstein/empirical) to protect against
mis-specified forecast distributions, while the local controllers
enforce tightened constraints and reject bounded disturbances during tracking.
Saberi et al.~\cite{saberi2021data} use this approach in a home-energy management context,
showing that a distributionally-robust hierarchical
coordinator preserves constraint
satisfaction and improves out-of-sample reliability
by explicitly accounting for distributional uncertainty
at the decision layer and delegating disturbance rejection to
the local controllers.

In the domain of hierarchical control for networked physical systems,
the work by Nandakumar et al.~\cite{nandakumar2024enhancing} demonstrates a data-driven
predictive droop-control architecture structured hierarchically
applied to islanded microgrids. 
The high-level module uses a physics-informed sparse identification
prediction model and model predictive control to issue
set-points for frequency regulation,
while the droop control at the lower level tracks those
references and compensates disturbances. 
Reachability analysis is employed to bound worst-case deviations, 
thereby contributing robustness guarantees
under modelling uncertainty and disturbance.
Robustness is achieved through 
adaptive model refinement and time-scale separation, 
the upper layer continuously re-identifying system dynamics,
while the lower predictive droop layer enforces
bounded invariance through reachability-based compensation.

\subsubsection{Safety}


Hierarchical Multi-Agent Reinforcement Learning 
can be made to provide near-perfect safety guarantees
using Control Barrier functions,
addressing the control problem at the level of learning joint cooperative behavior
and of learning safe individual behavior~\cite{ahmad2025hierarchical}.


As for an MPC approach, Vallon et al.~\cite{vallon2022data} propose a hierarchical, data-driven predictive control architecture for unknown operational environments, where previous task-trajectories are mined offline to generate target regions and input constraints that become terminal sets for a lower-level model predictive controller.
This target-set construction ensures that the tracking controller always steers the system into a region known safe 
(via prior data) before executing new environment-specific maneuvers.
In hierarchical terms this corresponds to the supervisory layer computing 
safe-set so-called waypoints or regions informed by data-driven transfer of
experience and the local layer running an MPC whose terminal set is
the safe region, thereby guaranteeing closed-loop feasibility and safety.
The safety guarantees thus stem from embedding experience-derived safe sets as terminal constraints in the hierarchical control scheme.



%\subsection{Higher Level Control}
%
%
%While most data-driven control efforts for 
%large-scale systems focus on the microscopic 
%level of node control, there is increasing 
%recognition that higher levels of abstraction 
%can provide leverage for scalability and robustness. 
%Specifically, edge control and structural control 
%have emerged as two promising approaches to orchestrating 
%collective behavior in complex systems~\cite{ControllingComplexSystem}. 
%These approaches shift attention from 
%direct state manipulation of individual nodes to 
%the design of interactions and the adaptation 
%of system topology, providing a macroscopic handle 
%on global dynamics.


%\subsubsection{Consensus/synchronization controllers and distributed optimization}

%\subsubsection{Event-triggered and sampled/quantized coordination}




%\section{Safety \& Certification at Scale}

%A continuing challenge in the field of data-driven control remains the question of verifyable safety.
%In many application areas of control theory, guarantees are required for methods to have any use at all.




%\subsection{Stability \& Robustness}
%
%Stability refers to the system's ability to remain bounded 
%and to return to equilibrium after small perturbations. 
%Formally, a system \(\dot{x} = f_u(x) , x \in \mathcal{X}\)
%is stable at its equilibrium point \(x_e\in \mathcal{X}\)
%if 
%\begin{equation}
%\forall \epsilon > 0 \exists \delta_\epsilon \forall t: ||x(0) - x_e||_2 < \delta_\epsilon
%\implies ||(x(t)-x_e)||_2 < \epsilon
%\end{equation}
%
%There are, among others, similar notions of asymptotical and exponential stability~\cite{min2023data}.
%
%
%
%\subsubsection{Lyapunov approaches}
%
%Lyapunov theory is one of the most popular techniques to
%analyse stability of control systems~\cite{li2023survey}.
%
%%Especially suited for large-scale systems is the composite Lyapunov function method,
%%using a composite Lyapunov function constructed as a weighted sum of isolated subsystems' Lyapunov functions.
%%https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10106217
%
%Min et al.~\cite{min2023data} propose Control with Inherent Lyapunov Stability (CoILS), a technique that 
%jointly learns a controlled dynamical
%systems model and a feedback controller from data.
%The key innovation is that the model is guaranteed by construction to
%be stabilized in closed-loop with the learned controller.
%This is achieved by constraining the open-loop dynamics onto the 
%subspace of dynamics stabilizable in closed-loop by
%the learned controller through the concurrent learning of a  parametric Lyapunov function,
%leading to the inherent guarantee of exponential stability of
%the learned models.
%
%%While Lyapunov-based approaches such as CoILS 
%%enable provable stability for small and medium-scale
%%systems, scalability to large-scale interconnected
%%systems remains an open frontier. Data-driven
%%large-scale control must address coupled uncertainties,
%%distributed dynamics, and limited data per subsystem, all of which complicate robustness guarantees.
%%
%%A promising research direction is distributed and compositional Lyapunov analysis. 
%%Instead of deriving a global Lyapunov function, 
%%each subsystem learns a local Lyapunov function 
%%\(V_i(x_i)\) from data, 
%%with interconnection terms bounded via 
%%data-driven estimates of subsystem coupling. 
%%This leads to scalable, certifiable guarantees.
%%Such approaches scale linearly in the number of
%%subsystems and are compatible with
%%decentralized DeePC or multi-agent RL controllers.
%%
%%Lavaei et al. [2] developed a data-driven
%%dissipativity framework for compositional
%%safety verification of interconnected systems:
%%local storage functions are identified from trajectory data and
%%composed to certify global dissipativity.
%%These techniques scale linearly with the number of
%%subsystems and naturally exploit system sparsity.
%
%\subsubsection{Contraction Theory}
%
%
%

%e based on a receding-horizon open-loop optimal control problem, which is guaranteed to be solvable
%and ensures constraint satisfaction at every control sampling time step. 



%\begin{figure}[h]
%\begin{center}
%\includegraphics{./images/grins.pdf}
%\end{center}
%\caption{A vector graphic loaded from a PDF file}
%\label{Pic1}
%\end{figure}

%\begin{figure}[h]
%\begin{center}
%\includegraphics{./images/grins.png}
%\end{center}
%\caption{A bitmap graphic loaded from a PNG file}
%\label{Pic2}
%\end{figure}


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results.}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



\section{Conclusion}\label{conclusion}


Data-driven control has become a central tool for addressing the scalability and modeling challenges inherent 
to large-scale dynamical systems. 
By shifting the emphasis from first-principles modeling to information extracted directly from data,
these methods enable control designs that would be infeasible with traditional approaches alone.
This survey reviewed the main paradigms in data-driven control, spanning data-driven modeling,
direct model-free control, and the architectural choices required to deploy such methods at scale.

A recurring theme across the literature is that scalability is
rarely achieved by a single algorithmic idea. 
Instead, practical large-scale control solutions combine dimensionality
reduction, structural decomposition, and appropriate control architectures such as decentralized, distributed, or hierarchical schemes. 
While data-driven methods can significantly reduce modeling effort and
improve flexibility, they introduce new challenges related to data quality, computational complexity, and performance guarantees.

Despite substantial progress, several open problems remain.
These include XXXXXX.
Addressing these challenges will be critical for moving data-driven control toward broadly applicable, reliable solutions for real-world large-scale systems.

% conference papers do not normally have an appendix


% use section* for acknowledgement
% \section*{Acknowledgment}
% The authors would like to thank...





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}



% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\printbibliography

%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}




% that's all folks
\end{document}


